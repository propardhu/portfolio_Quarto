{"title":"Grad-CAM Visualisation of ResNet-50‚Äôs Decision Pathways","markdown":{"yaml":{"title":"Grad-CAM Visualisation of ResNet-50‚Äôs Decision Pathways","date":"2024-05-09","reading-time":"5 min read","categories":"grad-cam","image":"https://cdn-images-1.medium.com/max/800/0*i27wef8IfiIomVpR.jpg"},"containsRefs":false,"markdown":"\n\n[click here to read this in medium](https://guttikondaparthasai.medium.com/grad-cam-visualisation-of-resnet-50s-decision-pathways-d4d6a85f5a57?source=rss-2c47946b91eb------2)\n\n<p>Tracing ResNet-50 Focus trands with Grad-CAM.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/0*i27wef8IfiIomVpR.jpg\" /><figcaption><a href=\"https://azati.ai/image-detection-recognition-and-classification-with-machine-learning/\">https://azati.ai/image-detection-recognition-and-classification-with-machine-learning/</a></figcaption></figure><h4>Understanding How AI Sees the¬†Worldüåè</h4><p>Imagine an AI as an artist trying to paint a picture but first needing to decide what part of a scene is worth focusing on. In this article, we explore a tool called Grad-CAM, which helps us visualize what catches the AI‚Äôs attention when it looks at an image. This tool is particularly useful for understanding complex image recognition models like ResNet-50, a type of deep neural network renowned for its accuracy in identifying objects in¬†images.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/1*Lk3_wpLJaWUfrYHMvA1P4Q.jpeg\" /><figcaption>our input¬†Image</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/1*aseruXZUZ9k2egMOPSQzSw.png\" /><figcaption>sample output</figcaption></figure><h4>Getting Startedüôåüèª</h4><p>To start, we need an image. Think of it as the scene our AI artist is going to paint. We use a standard JPEG image for this purpose. Our AI, powered by a model called ResNet-50, processes this image not just as a whole but looks deeply at various parts to decide what it¬†sees.</p><h4>Peeking Into the AI‚Äôs Mind (Grad-Cam)üí°</h4><p>To peek into what the AI is focusing on, we use Grad-CAM. This tool generates heatmaps that overlay on the original image. These heatmaps change color in areas where the AI is paying more attention. Thus, by looking at these heatmaps, we can understand which parts of the image are most important for the AI‚Äôs decision-making.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*AG_M2Cgvhhv2yXyT\" /><figcaption>Photo by <a href=\"https://unsplash.com/@clemensvanlay?utm_source=medium&amp;utm_medium=referral\">Clemens van Lay</a> on¬†<a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><h4>Step-by-Step Through the¬†Code:-</h4><pre>.<br />‚îú‚îÄ‚îÄ ResNet50Vis.ipynb<br />‚îú‚îÄ‚îÄ sample.jpeg<br />‚îú‚îÄ‚îÄ result.gif(animated gif is here result)<br />‚îî‚îÄ‚îÄ images<br />    ‚îî‚îÄ‚îÄ (genarated images will be here)</pre><p>Here is the file structure so we have only ResNet50Vis.ipynb and sample.jpeg files will be in the working directory.</p><p><strong>Prepare Utils and Model Wrapping:<br /></strong>Here we are creating¬†reusable</p><pre>import warnings<br />warnings.filterwarnings('ignore')<br />from torchvision import transforms<br />from datasets import load_dataset<br />from pytorch_grad_cam import run_dff_on_image, GradCAM<br />from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget<br />from pytorch_grad_cam.utils.image import show_cam_on_image<br />from PIL import Image<br />import numpy as np<br />import cv2<br />import torch<br />import imageio<br />from typing import List, Callable, Optional<br /><br />image = Image.open('./sample.jpeg')<br />img_tensor = transforms.ToTensor()(image)<br /><br />class HuggingfaceToTensorModelWrapper(torch.nn.Module):<br />    def __init__(self, model):<br />        super(HuggingfaceToTensorModelWrapper, self).__init__()<br />        self.model = model<br /><br />    def forward(self, x):<br />        return self.model(x).logits<br /><br />def category_name_to_index(model, category_name):<br />    name_to_index = dict((v, k) for k, v in model.config.id2label.items())<br />    return name_to_index[category_name]<br />    <br />def run_grad_cam_on_image(model: torch.nn.Module,<br />                          target_layer: torch.nn.Module,<br />                          targets_for_gradcam: List[Callable],<br />                          reshape_transform: Optional[Callable],<br />                          input_tensor: torch.nn.Module=img_tensor,<br />                          input_image: Image=image,<br />                          method: Callable=GradCAM):<br />    with method(model=HuggingfaceToTensorModelWrapper(model),<br />                 target_layers=[target_layer],<br />                 reshape_transform=reshape_transform) as cam:<br />        repeated_tensor = input_tensor[None, :].repeat(len(targets_for_gradcam), 1, 1, 1)<br /><br />        batch_results = cam(input_tensor=repeated_tensor,<br />                            targets=targets_for_gradcam)<br />        results = []<br />        for grayscale_cam in batch_results:<br />            visualization = show_cam_on_image(np.float32(input_image)/255,<br />                                              grayscale_cam,<br />                                              use_rgb=True)<br />            visualization = cv2.resize(visualization,<br />                                       (visualization.shape[1]//2, visualization.shape[0]//2))<br />            results.append(visualization)<br />        return np.hstack(results)<br />    <br />    <br />def print_top_categories(model, img_tensor, top_k=5):<br />    logits = model(img_tensor.unsqueeze(0)).logits<br />    indices = logits.cpu()[0, :].detach().numpy().argsort()[-top_k :][::-1]<br />    for i in indices:<br />        print(f&quot;Predicted class {i}: {model.config.id2label[i]}&quot;)</pre><p><strong>Target Identification¬†:</strong></p><p>now lets set the target label for which we will be genarating heat maps. As per our input image our target lable will cairn, cairn¬†terrier</p><pre>from transformers import ResNetForImageClassification<br />model = ResNetForImageClassification.from_pretrained(&quot;microsoft/resnet-50&quot;)<br />targets_for_gradcam = [ClassifierOutputTarget(category_name_to_index(model, &quot;cairn, cairn terrier&quot;))]</pre><p><strong>Running Grad-CAM:</strong></p><p>Here we will be running gradCam on every stage of resnet50 and store the heatmap image to list_of_images.</p><pre>list_of_images = []<br />for i in model.resnet.encoder.stages:<br />    for j in i.layers:<br />        target_layer = j<br />        list_of_images.append(Image.fromarray(run_grad_cam_on_image(model=model,<br />                      target_layer=target_layer,<br />                      targets_for_gradcam=targets_for_gradcam,<br />                      reshape_transform=None)))<br />print_top_categories(model, img_tensor)</pre><p><strong>Visualization and Animation:</strong></p><p>Great now can creat gif with our list of¬†images.</p><pre>image_files = []<br />for i, img in enumerate(list_of_images):<br />    path = f'images/temp_image_{i}.png'<br />    img.save(path)<br />    image_files.append(path)<br />with imageio.get_writer('my_animation.gif', mode='I', duration=0.5) as writer:<br />    for filename in image_files:<br />        image = imageio.imread(filename)<br />        writer.append_data(image)<br />from IPython.display import Image, display<br />display(Image(filename='./my_animation.gif'))</pre><h4>Results:</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/250/1*Mhpf1CK8-YGJ4h5BWGmiWw.gif\" /><figcaption>result gif</figcaption></figure><h4>Insights:</h4><p>By using the gradient values of each pixel in the image, we have generated heatmaps for all 15 stages of the encoder. These 15 heatmaps have been collected in a folder named ‚Äòimages.‚Äô Subsequently, we created a GIF that illustrates how an algorithm shifts its focus within an¬†image.</p><p>Complete code is avaliable at <a href=\"https://github.com/propardhu/ResNet_50_Vis\"><strong>https://github.com/propardhu/ResNet_50_Vis</strong></a></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*G4nxyFNUBq2gKjRd\" /><figcaption>Photo by <a href=\"https://unsplash.com/@kellysikkema?utm_source=medium&amp;utm_medium=referral\">Kelly Sikkema</a> on¬†<a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p><a href=\"https://medium.com/@guttikondaparthasai\">Pardhu Guttikonda - Medium</a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d4d6a85f5a57\" width=\"1\" />\n","srcMarkdownNoYaml":"\n\n[click here to read this in medium](https://guttikondaparthasai.medium.com/grad-cam-visualisation-of-resnet-50s-decision-pathways-d4d6a85f5a57?source=rss-2c47946b91eb------2)\n\n<p>Tracing ResNet-50 Focus trands with Grad-CAM.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/800/0*i27wef8IfiIomVpR.jpg\" /><figcaption><a href=\"https://azati.ai/image-detection-recognition-and-classification-with-machine-learning/\">https://azati.ai/image-detection-recognition-and-classification-with-machine-learning/</a></figcaption></figure><h4>Understanding How AI Sees the¬†Worldüåè</h4><p>Imagine an AI as an artist trying to paint a picture but first needing to decide what part of a scene is worth focusing on. In this article, we explore a tool called Grad-CAM, which helps us visualize what catches the AI‚Äôs attention when it looks at an image. This tool is particularly useful for understanding complex image recognition models like ResNet-50, a type of deep neural network renowned for its accuracy in identifying objects in¬†images.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/1*Lk3_wpLJaWUfrYHMvA1P4Q.jpeg\" /><figcaption>our input¬†Image</figcaption></figure><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/500/1*aseruXZUZ9k2egMOPSQzSw.png\" /><figcaption>sample output</figcaption></figure><h4>Getting Startedüôåüèª</h4><p>To start, we need an image. Think of it as the scene our AI artist is going to paint. We use a standard JPEG image for this purpose. Our AI, powered by a model called ResNet-50, processes this image not just as a whole but looks deeply at various parts to decide what it¬†sees.</p><h4>Peeking Into the AI‚Äôs Mind (Grad-Cam)üí°</h4><p>To peek into what the AI is focusing on, we use Grad-CAM. This tool generates heatmaps that overlay on the original image. These heatmaps change color in areas where the AI is paying more attention. Thus, by looking at these heatmaps, we can understand which parts of the image are most important for the AI‚Äôs decision-making.</p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*AG_M2Cgvhhv2yXyT\" /><figcaption>Photo by <a href=\"https://unsplash.com/@clemensvanlay?utm_source=medium&amp;utm_medium=referral\">Clemens van Lay</a> on¬†<a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><h4>Step-by-Step Through the¬†Code:-</h4><pre>.<br />‚îú‚îÄ‚îÄ ResNet50Vis.ipynb<br />‚îú‚îÄ‚îÄ sample.jpeg<br />‚îú‚îÄ‚îÄ result.gif(animated gif is here result)<br />‚îî‚îÄ‚îÄ images<br />    ‚îî‚îÄ‚îÄ (genarated images will be here)</pre><p>Here is the file structure so we have only ResNet50Vis.ipynb and sample.jpeg files will be in the working directory.</p><p><strong>Prepare Utils and Model Wrapping:<br /></strong>Here we are creating¬†reusable</p><pre>import warnings<br />warnings.filterwarnings('ignore')<br />from torchvision import transforms<br />from datasets import load_dataset<br />from pytorch_grad_cam import run_dff_on_image, GradCAM<br />from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget<br />from pytorch_grad_cam.utils.image import show_cam_on_image<br />from PIL import Image<br />import numpy as np<br />import cv2<br />import torch<br />import imageio<br />from typing import List, Callable, Optional<br /><br />image = Image.open('./sample.jpeg')<br />img_tensor = transforms.ToTensor()(image)<br /><br />class HuggingfaceToTensorModelWrapper(torch.nn.Module):<br />    def __init__(self, model):<br />        super(HuggingfaceToTensorModelWrapper, self).__init__()<br />        self.model = model<br /><br />    def forward(self, x):<br />        return self.model(x).logits<br /><br />def category_name_to_index(model, category_name):<br />    name_to_index = dict((v, k) for k, v in model.config.id2label.items())<br />    return name_to_index[category_name]<br />    <br />def run_grad_cam_on_image(model: torch.nn.Module,<br />                          target_layer: torch.nn.Module,<br />                          targets_for_gradcam: List[Callable],<br />                          reshape_transform: Optional[Callable],<br />                          input_tensor: torch.nn.Module=img_tensor,<br />                          input_image: Image=image,<br />                          method: Callable=GradCAM):<br />    with method(model=HuggingfaceToTensorModelWrapper(model),<br />                 target_layers=[target_layer],<br />                 reshape_transform=reshape_transform) as cam:<br />        repeated_tensor = input_tensor[None, :].repeat(len(targets_for_gradcam), 1, 1, 1)<br /><br />        batch_results = cam(input_tensor=repeated_tensor,<br />                            targets=targets_for_gradcam)<br />        results = []<br />        for grayscale_cam in batch_results:<br />            visualization = show_cam_on_image(np.float32(input_image)/255,<br />                                              grayscale_cam,<br />                                              use_rgb=True)<br />            visualization = cv2.resize(visualization,<br />                                       (visualization.shape[1]//2, visualization.shape[0]//2))<br />            results.append(visualization)<br />        return np.hstack(results)<br />    <br />    <br />def print_top_categories(model, img_tensor, top_k=5):<br />    logits = model(img_tensor.unsqueeze(0)).logits<br />    indices = logits.cpu()[0, :].detach().numpy().argsort()[-top_k :][::-1]<br />    for i in indices:<br />        print(f&quot;Predicted class {i}: {model.config.id2label[i]}&quot;)</pre><p><strong>Target Identification¬†:</strong></p><p>now lets set the target label for which we will be genarating heat maps. As per our input image our target lable will cairn, cairn¬†terrier</p><pre>from transformers import ResNetForImageClassification<br />model = ResNetForImageClassification.from_pretrained(&quot;microsoft/resnet-50&quot;)<br />targets_for_gradcam = [ClassifierOutputTarget(category_name_to_index(model, &quot;cairn, cairn terrier&quot;))]</pre><p><strong>Running Grad-CAM:</strong></p><p>Here we will be running gradCam on every stage of resnet50 and store the heatmap image to list_of_images.</p><pre>list_of_images = []<br />for i in model.resnet.encoder.stages:<br />    for j in i.layers:<br />        target_layer = j<br />        list_of_images.append(Image.fromarray(run_grad_cam_on_image(model=model,<br />                      target_layer=target_layer,<br />                      targets_for_gradcam=targets_for_gradcam,<br />                      reshape_transform=None)))<br />print_top_categories(model, img_tensor)</pre><p><strong>Visualization and Animation:</strong></p><p>Great now can creat gif with our list of¬†images.</p><pre>image_files = []<br />for i, img in enumerate(list_of_images):<br />    path = f'images/temp_image_{i}.png'<br />    img.save(path)<br />    image_files.append(path)<br />with imageio.get_writer('my_animation.gif', mode='I', duration=0.5) as writer:<br />    for filename in image_files:<br />        image = imageio.imread(filename)<br />        writer.append_data(image)<br />from IPython.display import Image, display<br />display(Image(filename='./my_animation.gif'))</pre><h4>Results:</h4><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/250/1*Mhpf1CK8-YGJ4h5BWGmiWw.gif\" /><figcaption>result gif</figcaption></figure><h4>Insights:</h4><p>By using the gradient values of each pixel in the image, we have generated heatmaps for all 15 stages of the encoder. These 15 heatmaps have been collected in a folder named ‚Äòimages.‚Äô Subsequently, we created a GIF that illustrates how an algorithm shifts its focus within an¬†image.</p><p>Complete code is avaliable at <a href=\"https://github.com/propardhu/ResNet_50_Vis\"><strong>https://github.com/propardhu/ResNet_50_Vis</strong></a></p><figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/0*G4nxyFNUBq2gKjRd\" /><figcaption>Photo by <a href=\"https://unsplash.com/@kellysikkema?utm_source=medium&amp;utm_medium=referral\">Kelly Sikkema</a> on¬†<a href=\"https://unsplash.com?utm_source=medium&amp;utm_medium=referral\">Unsplash</a></figcaption></figure><p><a href=\"https://medium.com/@guttikondaparthasai\">Pardhu Guttikonda - Medium</a></p><img alt=\"\" height=\"1\" src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d4d6a85f5a57\" width=\"1\" />\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"2024-05-09-grad-cam-visualisation-of-resnet-50-s-decision-pathways.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.47","theme":{"light":["simplex","styles.scss"],"dark":["superhero","styles.scss"]},"toc-location":"left","title":"Grad-CAM Visualisation of ResNet-50‚Äôs Decision Pathways","date":"2024-05-09","reading-time":"5 min read","categories":"grad-cam","image":"https://cdn-images-1.medium.com/max/800/0*i27wef8IfiIomVpR.jpg"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}