[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Building an Advanced Image Search System with Machine Learning and ElasticSearch\n\n\n6 min\n\n\n\ncomputer-vision\n\n\n\n\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrad-CAM Visualisation of ResNet-50’s Decision Pathways\n\n\n7 min\n\n\n\ngrad-cam\n\n\n\n\n\n\n\nMay 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimplifying Kafka: Effortless Stream Processing with Docker\n\n\n4 min\n\n\n\nstreaming\n\n\n\n\n\n\n\nFeb 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFree & Easy Portfolio Launch: Customize and Host with GitHub and Netlify\n\n\n3 min\n\n\n\nportfolio\n\n\n\n\n\n\n\nNov 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNetwork Checklist for Unity VR Apps\n\n\n3 min\n\n\n\nunity\n\n\n\n\n\n\n\nOct 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage Processing using CNN\n\n\n5 min\n\n\n\nconvolutional-neural-net\n\n\n\n\n\n\n\nJul 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinary Tree Data Structure\n\n\n6 min\n\n\n\ngraph-traversal\n\n\n\n\n\n\n\nMar 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpring Data JPA\n\n\n4 min\n\n\n\njava-spring-boot\n\n\n\n\n\n\n\nNov 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCucumber with Selenium Automation\n\n\n7 min\n\n\n\ncucumber\n\n\n\n\n\n\n\nOct 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpring Boot Authentication and Authorization\n\n\n26 min\n\n\n\nspring-boot\n\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Partha Sai Guttikonda",
    "section": "",
    "text": "Welcome to my portfolio! 🚀 I’m Partha Sai Guttikonda, a dedicated and innovative Computational Biologist and Full-Stack Engineer with a deep passion for leveraging machine learning and high-performance computing to solve complex problems. 🧠💻 With a Master’s degree in Computer Science and Engineering from the University of Texas at Arlington and hands-on experience managing advanced GPU clusters and developing scalable web applications, I’ve successfully led projects that merge cutting-edge technology with practical applications. 🌟 Explore my work to see how I’ve contributed to advancements in medical imaging, cloud infrastructure optimization, and more. 🏥☁️ Let’s collaborate and push the boundaries of what’s possible! 🌐✨"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Partha Sai Guttikonda",
    "section": "",
    "text": "Welcome to my portfolio! 🚀 I’m Partha Sai Guttikonda, a dedicated and innovative Computational Biologist and Full-Stack Engineer with a deep passion for leveraging machine learning and high-performance computing to solve complex problems. 🧠💻 With a Master’s degree in Computer Science and Engineering from the University of Texas at Arlington and hands-on experience managing advanced GPU clusters and developing scalable web applications, I’ve successfully led projects that merge cutting-edge technology with practical applications. 🌟 Explore my work to see how I’ve contributed to advancements in medical imaging, cloud infrastructure optimization, and more. 🏥☁️ Let’s collaborate and push the boundaries of what’s possible! 🌐✨"
  },
  {
    "objectID": "index.html#areas-of-interest",
    "href": "index.html#areas-of-interest",
    "title": "Partha Sai Guttikonda",
    "section": "Areas of Interest",
    "text": "Areas of Interest\n🧠 Artificial Intelligence and Machine Learning\n🔬 Medical Imaging and Bioinformatics\n📊 Data Analysis and Visualization\n🚀 High-Performance Computing and GPU Utilization\n🌐 Cloud Computing and Infrastructure Optimization\n🔧 Software Development and Full-Stack Engineering\n📈 Predictive Modeling and Algorithm Development\n🔄 Automation of Data Pipelines and Workflows\n🌍 Environmental Impact and Sustainability\n🖥️ Computer Vision and Image Processing\n📚 Continuous Learning and Research in AI"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Partha Sai Guttikonda",
    "section": "Education",
    "text": "Education\nUniversity of Texas at Arlington | USA\nMSc in CSE | GPA: 3.99\nSreenidhi Institute of Technology | IND\nBTech in CSE | GPA: 3.89"
  },
  {
    "objectID": "publications/visvr.html",
    "href": "publications/visvr.html",
    "title": "SpatialVisVR:An Immersive, Multiplexed Medical Image Viewer With Contextual Similar-Patient Search",
    "section": "",
    "text": "IEEE CIBCB 2024\nIn modern pathology, multiplexed immunofluorescence (mIF) and multiplex immunohistochemistry (mIHC) bring both vast opportunities and challenges. These techniques illuminate complex tumor microenvironment interactions, necessitating intuitive visualization tools. With the rise of electronic health records (EHR) and information overload for physicians, integrating advanced technologies becomes essential. Enter SpatialVisVR: a versatile VR platform for comparing medical images, adaptable for data privacy on embedded hardware. Clinicians can capture pathology slides in real-time via mobile, then SpatialVisVR employs a deep learning algorithm to match and display similar mIF images. This interface allows for adding or removing up to 100 multiplexed protein channels, aiding immuno-oncology decisions. Ultimately, SpatialVisVR aims to refine diagnostic processes, promoting a holistic, efficient approach to immuno-oncology research and treatment. arxiv link"
  },
  {
    "objectID": "blog_posts/2022-11-27-spring-data-jpa.html",
    "href": "blog_posts/2022-11-27-spring-data-jpa.html",
    "title": "Spring Data JPA",
    "section": "",
    "text": "click here to read this in medium\n\nSpring Data JPA provides repository support for the Jakarta Persistence API (JPA).\n\n\n\n\nPhoto by Markus Spiske on Unsplash\n\n\n\nSpring Data JPA provides repository support for the Jakarta Persistence API(JPA).It is used to improve the implementation of data access layers by reducing the efforts to the amount that’s actually needed.\n\n\n⛹️‍♂️Dependencies\n\n\nThe below dependency needs to be in the build.gradle file.\n\n&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.data&lt;/groupId&gt;    &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt;  &lt;/dependency&gt;&lt;dependencies&gt;\n\n\n\nPhoto by Tracy Adams on Unsplash\n\n\n\n🙌🏻Basic concepts\n\n\nIn general, We use CrudRepository for the CREATE, READ, UPDATE and DELETE operations and PagingAndSortingRepository for pagination and sort records. In JpaRepository provides JPA related methods such as flushing the persistence context and delete records in a batch. So JpaRepository inherities both the CrudRepository and PagingAndSorting.Addtional to that it gives a different methods to filter, save and query from the repository.\n\n\n👉Creating Repository Interface:\n\n\nSo in this interface we can give the method names and spring will take care of logic in it.Note:- All the below example need to be inside these kind of interface which extends JpaRepository.\n\n@Repositorypublic interface ProductRepository extends JpaRepository&lt;Product, Long&gt; {    Product findByName(String productName);}\n\n\n\nPhoto by Aron Visuals on Unsplash\n\n\n\n🧞‍♂️Methods we can use in JPA\n\n\nCURD Operations and PagingAndSorting Operations:\n\n&lt;S extends T&gt; S save(S entity); //--&gt;save entity to DBOptional&lt;T&gt; findById(ID primaryKey); //--&gt;find entity from DBIterable&lt;T&gt; findAll();//--&gt;get ALLlong count();//--&gt; get count of entitiesvoid delete(T entity);// --&gt; delete an entityboolean existsById(ID primaryKey);// --&gt; is exist by IDIterable&lt;T&gt; findAll(Sort sort);Page&lt;T&gt; findAll(Pageable pageable);//example below  repository.findAll(PageRequest.of(1, 20));long countByLastname(String lastname); // we can use any field name in place of Lastnamelong deleteByLastname(String lastname);List&lt;User&gt; removeByLastname(String lastname);\n\nQuery Methods:\n\nList&lt;Person&gt; findByLastname(String lastname);Optional&lt;T&gt; findById(ID id);User findByEmailAddress(EmailAddress emailAddress);List&lt;Person&gt; findByEmailAddressAndLastname(EmailAddress emailAddress, String lastname);// Enables the distinct flag for the queryList&lt;Person&gt; findDistinctPeopleByLastnameOrFirstname(String lastname, String firstname);List&lt;Person&gt; findPeopleDistinctByLastnameOrFirstname(String lastname, String firstname);// Enabling ignoring case for an individual propertyList&lt;Person&gt; findByLastnameIgnoreCase(String lastname);// Enabling ignoring case for all suitable propertiesList&lt;Person&gt; findByLastnameAndFirstnameAllIgnoreCase(String lastname, String firstname);// Enabling static ORDER BY for a queryList&lt;Person&gt; findByLastnameOrderByFirstnameAsc(String lastname);List&lt;Person&gt; findByLastnameOrderByFirstnameDesc(String lastname);\n\nIn the above example we can create the methods in interface as we need using the Distinct flag, Ignore Case and order BY. Also, we can use And, Or to pass multiple parameters to the method.\n\n\nProperty Expressions:\n\n\nIf you have a case where you want to get a entity based on nested property for example we want to get list of People who has a given zipcode, Zipcode is present inside Address. So this case we can use the below code.\n\nList&lt;Person&gt; findByAddressZipCode(ZipCode zipCode);//better wayList&lt;Person&gt; findByAddress_ZipCode(ZipCode zipCode);//also correct\n\nSpecial Parameter handling:\n\nPage&lt;User&gt; findByLastname(String lastname, Pageable pageable);Slice&lt;User&gt; findByLastname(String lastname, Pageable pageable);List&lt;User&gt; findByLastname(String lastname, Sort sort);List&lt;User&gt; findByLastname(String lastname, Pageable pageable);//SORT exampleSort sort = Sort.by(\"firstname\").ascending()  .and(Sort.by(\"lastname\").descending());TypedSort&lt;Person&gt; person = Sort.sort(Person.class);Sort sort = person.by(Person::getFirstname).ascending()  .and(person.by(Person::getLastname).descending());\n\nLimiting Query Results:\n\nUser findFirstByOrderByLastnameAsc();User findTopByOrderByAgeDesc();Page&lt;User&gt; queryFirst10ByLastname(String lastname, Pageable pageable);Slice&lt;User&gt; findTop3ByLastname(String lastname, Pageable pageable);List&lt;User&gt; findFirst10ByLastname(String lastname, Sort sort);List&lt;User&gt; findTop10ByLastname(String lastname, Pageable pageable);\n\nStreamble:\n\n\nNow I came across a point where we need to get entities based on condition if name contains two letters in it I need them.\n\ninterface PersonRepository extends Repository&lt;Person, Long&gt; {  Streamable&lt;Person&gt; findByFirstnameContaining(String firstname);  Streamable&lt;Person&gt; findByLastnameContaining(String lastname);}Streamable&lt;Person&gt; result = repository.findByFirstnameContaining(\"av\")  .and(repository.findByLastnameContaining(\"ea\"));\n\nStreaming Query Results:\n\n\nWe can run the Query as below.\n\n@Query(\"select u from User u\")Stream&lt;User&gt; findAllByCustomQueryAndStream();Stream&lt;User&gt; readAllByFirstnameNotNull();@Query(\"select u from User u\")Stream&lt;User&gt; streamAllPaged(Pageable pageable);\n\n\n\nPhoto by Sai Kiran Anagani on Unsplash\n\n\n\nAsynchronous Query Results:\n\n\nAsynchronous way to run Queries.\n\n@AsyncFuture&lt;User&gt; findByFirstname(String firstname);@AsyncCompletableFuture&lt;User&gt; findOneByFirstname(String firstname);//useageCompletableFuture&lt;User&gt; user= findByFirstname(\"Macintosh\");user(System.out::println);\n\nReferances:\n\n\ndocs.spring.io/spring-data/jpa/docs/current/reference/html/#repositories.core-concepts\n\n\nPardhu Guttikonda - Medium\n\n\n\n\nPhoto by Wilhelm Gunkel on Unsplash"
  },
  {
    "objectID": "blog_posts/2024-05-09-grad-cam-visualisation-of-resnet-50-s-decision-pathways.html",
    "href": "blog_posts/2024-05-09-grad-cam-visualisation-of-resnet-50-s-decision-pathways.html",
    "title": "Grad-CAM Visualisation of ResNet-50’s Decision Pathways",
    "section": "",
    "text": "click here to read this in medium\n\nTracing ResNet-50 Focus trands with Grad-CAM.\n\n\n\n\nhttps://azati.ai/image-detection-recognition-and-classification-with-machine-learning/\n\n\n\nUnderstanding How AI Sees the World🌏\n\n\nImagine an AI as an artist trying to paint a picture but first needing to decide what part of a scene is worth focusing on. In this article, we explore a tool called Grad-CAM, which helps us visualize what catches the AI’s attention when it looks at an image. This tool is particularly useful for understanding complex image recognition models like ResNet-50, a type of deep neural network renowned for its accuracy in identifying objects in images.\n\n\n\n\nour input Image\n\n\n\n\n\nsample output\n\n\n\nGetting Started🙌🏻\n\n\nTo start, we need an image. Think of it as the scene our AI artist is going to paint. We use a standard JPEG image for this purpose. Our AI, powered by a model called ResNet-50, processes this image not just as a whole but looks deeply at various parts to decide what it sees.\n\n\nPeeking Into the AI’s Mind (Grad-Cam)💡\n\n\nTo peek into what the AI is focusing on, we use Grad-CAM. This tool generates heatmaps that overlay on the original image. These heatmaps change color in areas where the AI is paying more attention. Thus, by looking at these heatmaps, we can understand which parts of the image are most important for the AI’s decision-making.\n\n\n\n\nPhoto by Clemens van Lay on Unsplash\n\n\n\nStep-by-Step Through the Code:-\n\n.├── ResNet50Vis.ipynb├── sample.jpeg├── result.gif(animated gif is here result)└── images    └── (genarated images will be here)\n\nHere is the file structure so we have only ResNet50Vis.ipynb and sample.jpeg files will be in the working directory.\n\n\nPrepare Utils and Model Wrapping:Here we are creating reusable\n\nimport warningswarnings.filterwarnings('ignore')from torchvision import transformsfrom datasets import load_datasetfrom pytorch_grad_cam import run_dff_on_image, GradCAMfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTargetfrom pytorch_grad_cam.utils.image import show_cam_on_imagefrom PIL import Imageimport numpy as npimport cv2import torchimport imageiofrom typing import List, Callable, Optionalimage = Image.open('./sample.jpeg')img_tensor = transforms.ToTensor()(image)class HuggingfaceToTensorModelWrapper(torch.nn.Module):    def __init__(self, model):        super(HuggingfaceToTensorModelWrapper, self).__init__()        self.model = model    def forward(self, x):        return self.model(x).logitsdef category_name_to_index(model, category_name):    name_to_index = dict((v, k) for k, v in model.config.id2label.items())    return name_to_index[category_name]    def run_grad_cam_on_image(model: torch.nn.Module,                          target_layer: torch.nn.Module,                          targets_for_gradcam: List[Callable],                          reshape_transform: Optional[Callable],                          input_tensor: torch.nn.Module=img_tensor,                          input_image: Image=image,                          method: Callable=GradCAM):    with method(model=HuggingfaceToTensorModelWrapper(model),                 target_layers=[target_layer],                 reshape_transform=reshape_transform) as cam:        repeated_tensor = input_tensor[None, :].repeat(len(targets_for_gradcam), 1, 1, 1)        batch_results = cam(input_tensor=repeated_tensor,                            targets=targets_for_gradcam)        results = []        for grayscale_cam in batch_results:            visualization = show_cam_on_image(np.float32(input_image)/255,                                              grayscale_cam,                                              use_rgb=True)            visualization = cv2.resize(visualization,                                       (visualization.shape[1]//2, visualization.shape[0]//2))            results.append(visualization)        return np.hstack(results)        def print_top_categories(model, img_tensor, top_k=5):    logits = model(img_tensor.unsqueeze(0)).logits    indices = logits.cpu()[0, :].detach().numpy().argsort()[-top_k :][::-1]    for i in indices:        print(f\"Predicted class {i}: {model.config.id2label[i]}\")\n\nTarget Identification :\n\n\nnow lets set the target label for which we will be genarating heat maps. As per our input image our target lable will cairn, cairn terrier\n\nfrom transformers import ResNetForImageClassificationmodel = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")targets_for_gradcam = [ClassifierOutputTarget(category_name_to_index(model, \"cairn, cairn terrier\"))]\n\nRunning Grad-CAM:\n\n\nHere we will be running gradCam on every stage of resnet50 and store the heatmap image to list_of_images.\n\nlist_of_images = []for i in model.resnet.encoder.stages:    for j in i.layers:        target_layer = j        list_of_images.append(Image.fromarray(run_grad_cam_on_image(model=model,                      target_layer=target_layer,                      targets_for_gradcam=targets_for_gradcam,                      reshape_transform=None)))print_top_categories(model, img_tensor)\n\nVisualization and Animation:\n\n\nGreat now can creat gif with our list of images.\n\nimage_files = []for i, img in enumerate(list_of_images):    path = f'images/temp_image_{i}.png'    img.save(path)    image_files.append(path)with imageio.get_writer('my_animation.gif', mode='I', duration=0.5) as writer:    for filename in image_files:        image = imageio.imread(filename)        writer.append_data(image)from IPython.display import Image, displaydisplay(Image(filename='./my_animation.gif'))\n\nResults:\n\n\n\n\nresult gif\n\n\n\nInsights:\n\n\nBy using the gradient values of each pixel in the image, we have generated heatmaps for all 15 stages of the encoder. These 15 heatmaps have been collected in a folder named ‘images.’ Subsequently, we created a GIF that illustrates how an algorithm shifts its focus within an image.\n\n\nComplete code is avaliable at https://github.com/propardhu/ResNet_50_Vis\n\n\n\n\nPhoto by Kelly Sikkema on Unsplash\n\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2024-05-22-building-an-advanced-image-search-system-with-machine-learning-and-elasticsearch.html",
    "href": "blog_posts/2024-05-22-building-an-advanced-image-search-system-with-machine-learning-and-elasticsearch.html",
    "title": "Building an Advanced Image Search System with Machine Learning and ElasticSearch",
    "section": "",
    "text": "click here to read this in medium\n\nIn today’s digital world, having a powerful image search system is invaluable. Imagine being able to search for images using other images rather than keywords. This article will guide you through building such an advanced image search system using machine learning techniques. We’ll leverage OpenAI’s CLIP model to process images into feature vectors and Elasticsearch (part of the ELK stack) to store and search these vectors using cosine similarity.\n\n\n\n\npic by me❤️\n\n\n\nUnderstanding Image Search with Machine Learning\n\n\nWhat is Image Search?\n\n\nImage search is the process of finding images that are visually similar to a query image. Traditional image search engines rely on metadata or keywords associated with images. However, with advancements in machine learning, we can now search for images based on their visual content.\n\n\nHow Does it Work?\n\n\n\nFeature Extraction: Transform images into feature vectors that capture their visual content.\n\n\nIndexing: Store these feature vectors in a database.\n\n\nSearching: Compare feature vectors using a similarity metric (e.g., cosine similarity) to find the most similar images.\n\n\n\n\n\nPhoto by Patrick Tomasso on Unsplash\n\n\n\nOur Approach: Using CLIP and Elasticsearch\n\n\nWhat is CLIP?\n\n\nCLIP (Contrastive Language–Image Pre-Training) is a model developed by OpenAI that can understand images and text in a unified manner. It can transform an image into a feature vector that encapsulates the image’s visual content.\n\n\nWhy Elasticsearch?\n\n\nElasticsearch is a powerful search engine that supports efficient storage and querying of large datasets. With the k-NN (k-nearest neighbors) feature, Elasticsearch can quickly find similar vectors, making it ideal for our image search system.\n\n\n\n\nPhoto by Suzi Kim on Unsplash\n\n\n\nStep-by-Step Implementation\n\n\nStep 1: Set Up the ELK Stack Using Docker\n\n\nFirst, we need to set up Elasticsearch and Kibana using Docker.For setting up the ElasticSearch, Logstash and Kibana. Please clone this repo (https://github.com/propardhu/Docker_ELK_Image_Search) and compose up the setup.Verify the setup:Elasticsearch: http://localhost:9200Kibana: http://localhost:5601username: elasticpassword: changeme\n\n\nStep 2: Prepare and Index Images Using Python\n\n\nNext, we will prepare and index images into Elasticsearch using the Oxford Pets dataset.\n\n\n2.1. Install Dependencies\n\n!pip install torch transformers pillow requests torchvision matplotlib\n\n2.2. Download and Preprocess the Oxford Pets Dataset\n\nimport torchfrom transformers import CLIPProcessor, CLIPModelfrom PIL import Imageimport requestsimport jsonimport osfrom torchvision import datasets, transformsfrom torch.utils.data import DataLoader, Subset# Load the CLIP model and processormodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")# Function to preprocess images and extract featuresdef extract_features(image):    inputs = processor(images=image, return_tensors=\"pt\")    with torch.no_grad():        image_features = model.get_image_features(**inputs)    image_features = image_features / image_features.norm(dim=-1, keepdim=True)    return image_features.squeeze().tolist()# Directory to save the datasetdataset_dir = \"./oxford_pets\"# Download and prepare the dataset (using Oxford Pets for demo)transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])dataset = datasets.OxfordIIITPet(root=dataset_dir, download=True, transform=transform)# Take a subset of 100 imagessubset_indices = list(range(100))subset = Subset(dataset, subset_indices)data_loader = DataLoader(subset, batch_size=1, shuffle=False)# Ensure there are at least 100 imagesassert len(subset) &gt;= 100, \"Dataset should contain at least 100 images.\"\n\n2.3. Index Features in Elasticsearch\n\n# Elasticsearch settingsES_HOST = \"http://localhost:9200\"ES_INDEX = \"image-index\"ES_USER = \"elastic\"ES_PASS = \"changeme\"def index_image(image, label, image_id):    features = extract_features(image)    document = {        \"name\": f\"image_{image_id}\",        \"label\": label,        \"vector\": features    }    response = requests.post(        f\"{ES_HOST}/{ES_INDEX}/_doc/{image_id}\",        headers={\"Content-Type\": \"application/json\"},        auth=(ES_USER, ES_PASS),        data=json.dumps(document)    )    return response.json()# Index the images with labelsfor i, (image, label) in enumerate(data_loader):    # Convert tensor to PIL image    image = transforms.ToPILImage()(image[0])    label = dataset.classes[label]    result = index_image(image, label, i)    image_path = os.path.join(dataset_dir, f\"image_{i}.jpg\")    image.save(image_path)  # Save the image for later retrieval    print(f\"Indexed image {i} with label '{label}': {result}\")\n\nStep 3: Perform Image-to-Image Search and Display Images\n\n\n3.1. Search for Similar Images\n\nimport matplotlib.pyplot as plt# Function to search for similar imagesdef search_similar_images(query_image_path, k=5):    query_image = Image.open(query_image_path)    query_features = extract_features(query_image)    search_query = {        \"knn\": {            \"field\": \"vector\",            \"query_vector\": query_features,            \"k\": k,            \"num_candidates\": 100        }    }    response = requests.post(        f\"{ES_HOST}/{ES_INDEX}/_knn_search\",        headers={\"Content-Type\": \"application/json\"},        auth=(ES_USER, ES_PASS),        data=json.dumps(search_query)    )    return response.json()# Function to display imagesdef display_images(query_image_path, search_results):    query_image = Image.open(query_image_path)    fig, axes = plt.subplots(1, 6, figsize=(20, 5))    # Display the query image    axes[0].imshow(query_image)    axes[0].set_title(\"Query Image\")    axes[0].axis('off')    # Display the top 5 similar images    for i, hit in enumerate(search_results['hits']['hits']):        image_id = hit['_id']        label = hit['_source']['label']        similar_image_path = os.path.join(dataset_dir, f\"image_{image_id}.jpg\")                similar_image = Image.open(similar_image_path)        axes[i + 1].imshow(similar_image)        axes[i + 1].set_title(f\"Label: {label}\\nScore: {hit['_score']:.2f}\")        axes[i + 1].axis('off')    plt.show()# Example search with a query image from the datasetfrom random import randintquery_image, _ = subset[randint(1, 100)]query_image = transforms.ToPILImage()(query_image)  # Convert tensor to PIL imagequery_image_path = \"./query_image.jpg\"  # Save the query image to this pathquery_image.save(query_image_path)  # Save the PIL image to the specified pathquery_result = search_similar_images(query_image_path)# Display the resultsdisplay_images(query_image_path, query_result)\n\n\n\nSample result-1\n\n\n\n\n\nSample result-2\n\n\n\nNote: I have created An flask app to show the search results.\n\n\nAll the code is available at\n\n\nGitHub - propardhu/Docker_ELK_Image_Search\n\n\nConclusion\n\n\nIn this article, we built an advanced image search system using OpenAI’s CLIP model and Elasticsearch. By setting up the ELK stack with Docker, downloading and preparing the Oxford Pets dataset, indexing image features into Elasticsearch, and performing image.\n\n\nThank you..!\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2024-02-18-simplifying-kafka-effortless-stream-processing-with-docker.html",
    "href": "blog_posts/2024-02-18-simplifying-kafka-effortless-stream-processing-with-docker.html",
    "title": "Simplifying Kafka: Effortless Stream Processing with Docker",
    "section": "",
    "text": "click here to read this in medium\n\nUnlock the power of real-time data processing with Apache Kafka, and streamline your setup with Docker for an efficient, scalable solution.\n\n\n\n\nPhoto by Hunter Harritt on Unsplash\n\n\n\nIntroduction to Apache Kafka\n\n\nImagine a river, endlessly flowing with data from countless sources. This is the world of streaming data, and navigating it requires a robust and efficient system. Enter Apache Kafka: a powerhouse designed to manage and process vast streams of real-time data. Kafka acts as an organizing force, ensuring every bit of data is processed systematically, maintaining order in the relentless stream of information.\n\n\nExploring Kafka, Zookeeper, and Fault Tolerance\n\n\nTo truly harness the capabilities of Kafka, along with its components like Zookeeper and its fault tolerance mechanisms, it’s essential to delve into the core concepts and functionalities that make Kafka a critical tool in data streaming and processing. More info on this topic this.\n\n\nThe Role of Kafka as Storage\n\n\nThe question arises: beyond its primary role, can Kafka be utilized as a storage system? This exploration reveals Kafka’s capabilities beyond real-time data processing. More info on this topic here.\n\n\nKey Terminology in Kafka\n\n\nFamiliarizing yourself with Kafka’s terminology is crucial for navigating its ecosystem:\n\n\n\nTopic: A specific channel where data flows, categorized under a feed name.\n\n\nPartition: A segment within a topic for scalability, allowing parallel data consumption.\n\n\nReplica: Partition clones for fault tolerance, ensuring data availability.\n\n\nProducer: Applications that send data to Kafka, deciding on the partition for each record.\n\n\nConsumer: Applications that read and process the data stream from topics.\n\n\nConsumer Group: A collection of consumers sharing an identifier to divide processing workload.\n\n\nBroker: The heart of the Kafka cluster, managing data storage and communication.\n\n\nZookeeper: Coordinates Kafka’s brokers, managing configuration and synchronization.\n\n\nOffset: A unique identifier for each record within a partition.\n\n\nLeader and Followers: Designations within replicas for handling requests and ensuring data integrity.\n\n\n\nDeploying Kafka with Docker\n\n\nWe leverage Confluent’s open-source Kafka images for a Docker-based approach, simplifying Kafka deployment and making stream processing power readily accessible.\n\n\n\n\nPhoto by Brett Jordan on Unsplash\n\n\n\nPractical Kafka Deployment: Docker and Python\n\n\nTo provide a hands-on example, we’ve prepared a comprehensive setup including a Docker Compose file and Python scripts for message handling.\n\n\nExplore Our GitHub Repository\n\n\nAccess the necessary files on our GitHub repository:\n\n📦POC_Kafka_python ┣ 📂connectors ┣ 📜.gitattributes ┣ 📜LICENSE ┣ 📜README.md ┣ 📜conduktor.yml ┣ 📜consumer.py ┣ 📜docker-compose.yml ┗ 📜producer.py\n\n\ndocker-compose.yml: Sets up the Confluent Kafka environment in Docker containers.\n\n\n\nPython Scripts:\n\n\n\nProducer Script: Sends 100 messages per second to a Kafka topic, showcasing Kafka’s high-volume handling.\n\n\nConsumer Script: Receives and processes messages from the Kafka topic in real-time.\n\n\n\nGetting Started\n\n\n1.Clone the Repository: Access all files for a Docker-based Kafka deployment.\n\ngit clone https://github.com/propardhu/POC_Kafka_python.git\n\n2. Launch Kafka with Docker Compose: Start the Kafka environment using.Docker Compose.\n\ncd POC_Kafka_python\n\nNow setup your username and password for the admin portal at conduktor.yml\n\nCDK_ORGANIZATION_NAME: \"python_demo_medium\"CDK_ADMIN_EMAIL: \"admin@admin.io\"CDK_ADMIN_PASSWORD: \"admin\"# in conduktor.yml\n\nNow get the docker up and running\n\ndocker compose -f docker-compose.yml up\n\ndashboard will be running at http://localhost:8080/\n\n\n\n\ndocker ran success\n\n\n\n\n\ndashboard\n\n\n\n3.Execute the Python Scripts: Begin sending and receiving messages with Kafka by running the Python scripts.\n\n\nrun the two python file in two different terminals to see live streaming.\n\npython producer.pypython consumer.py\nhttps://medium.com/media/08b30bbfe5eb7c9dfe4557793f4f0931/href\n\nThis practical setup showcases Kafka’s capabilities within a Docker environment, emphasizing real-world applications of streaming data management.\n\n\nWhat’s Next?\n\n\nAs we continue to explore the vast potential of Kafka, our journey into the world of stream processing and data handling is far from over. Stay tuned for our upcoming articles, where we will take a deeper dive into advanced integrations and applications of Kafka:\n\n\n\nIntegrating Kafka with Spring Boot and Camel: Our next guides will delve into creating sophisticated messaging applications by leveraging Kafka with Spring Boot and Apache Camel. This integration will provide a powerful foundation for building robust, scalable applications that can process and route data efficiently.\n\n\nHarnessing Unsupervised Learning in Kafka Networks: Beyond traditional applications, we’re venturing into the cutting-edge territory of machine learning. We will explore how unsupervised learning algorithms can be integrated into the Kafka network. This initiative aims to uncover insights from the diverse kinds of data streaming through Kafka. By applying machine learning, we can automate the identification of patterns, anomalies, and trends within the data, enhancing the intelligence and adaptability of our systems.\n\n\n\nThese upcoming articles will not only expand your toolkit but also open new horizons for innovation within your Kafka deployments. Whether it’s through advanced application integrations or the pioneering application of machine learning, the goal is to unlock new levels of efficiency, insight, and functionality in your data streaming projects.\n\n\n\n\nPhoto by Priscilla Du Preez 🇨🇦 on Unsplash\n\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2023-10-13-network-checklist-for-unity-vr-apps.html",
    "href": "blog_posts/2023-10-13-network-checklist-for-unity-vr-apps.html",
    "title": "Network Checklist for Unity VR Apps",
    "section": "",
    "text": "click here to read this in medium\n\nChecklist for Internet Connection in Unity VR App Builds\n\n\n\n\nPhoto by XR Expo on Unsplash\n\n\n\nWhile working on a Unity VR app for the Meta Quest, I encountered a peculiar issue. The app functioned seamlessly in debug mode on my development machine. However, when I built and installed it on the Meta Quest, the log highlighted an internet-related problem, stating, “cannot resolve the host name.” I’ve observed numerous threads on Unity communities discussing this very issue. In this article, I’ll share a checklist that has helped me address network connectivity challenges.\n\n\nCheck List:\n\n\n\nEnsure the VR device has an active Internet connection.\n\n\nReview the AndroidManifest.xml for the necessary network permissions.\n\n\nExplore the Meta support options.\n\n\n\n\n\nPhoto by Sara Kurig on Unsplash\n\n\n\nSetps:\n\n\n\nEnable the manual Main Manifest in the settings:Navigate to: File &gt; Build Settings &gt; Player Settings\n\n\n\n\n\nmy source\n\n\n\n\nIn the Player Settings, follow these steps:Go to: Player &gt; Other Settings &gt; ConfigurationChange the Internet Access to “Required.”If necessary, enable the “Allow Http” options.\n\n\n\n\n\n\nMost of the time, the app should function correctly after these adjustments. If not, enable the manual Main Manifest and inspect the file for network permissions. This option can be found at: Player &gt; Publishing Settings &gt; Build\n\n\n\n\n\nLook for these lines inside the &lt;manifest&gt; tag but outside the &lt;application&gt; tag:\n\n&lt;uses-permission android:name=\"android.permission.INTERNET\" /&gt;&lt;uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" /&gt;\n\nHere’s an example of what your AndroidManifest.xml might look like:\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;manifest xmlns:android=\"http://schemas.android.com/apk/res/android\"    package=\"com.unity3d.player\"    xmlns:tools=\"http://schemas.android.com/tools\"    android:versionCode=\"1\"    android:versionName=\"1.0\"&gt;    &lt;uses-permission android:name=\"android.permission.INTERNET\" /&gt;    &lt;uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" /&gt;    &lt;application&gt;        &lt;activity android:name=\"com.unity3d.player.UnityPlayerActivity\"            android:theme=\"@style/UnityThemeSelector\"&gt;            &lt;intent-filter&gt;                &lt;action android:name=\"android.intent.action.MAIN\" /&gt;                &lt;category android:name=\"android.intent.category.LAUNCHER\" /&gt;            &lt;/intent-filter&gt;            &lt;meta-data android:name=\"unityplayer.UnityActivity\" android:value=\"true\" /&gt;        &lt;/activity&gt;    &lt;/application&gt;&lt;/manifest&gt;\n\nIf the app still doesn’t connect, double-check the settings mentioned above.\n\n\n\n\n\n\n\n\nThank you for reading! I hope this guide proves helpful.\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2023-11-19-free-easy-portfolio-launch-customize-and-host-with-github-and-netlify.html",
    "href": "blog_posts/2023-11-19-free-easy-portfolio-launch-customize-and-host-with-github-and-netlify.html",
    "title": "Free & Easy Portfolio Launch: Customize and Host with GitHub and Netlify",
    "section": "",
    "text": "click here to read this in medium\n\n\n\n\nIntroduction :\n\n\nDiscover the simplest way to put your talents on display — for free! This guide is your key to creating an attractive portfolio by customizing a GitHub repository and hosting it on Netlify, without spending a penny. Ideal for anyone looking to establish a professional online presence without the complexities of coding or software installation.\n\n\nSection 1:Preparing Your Environment\n\n\nRequirements: All you need is a GitHub account and a zest for creativity! This process requires no financial investment or advanced technical skills.Overview of Tools Used: We’ll be using GitHub for your codebase and Netlify for web hosting — both available at no cost.\n\n\n\n\nPhoto by Ian Schneider on Unsplash\n\n\n\nSection 2: Forking the GitHub Repository\n\n\nStep-by-Step Guide to Forking: Select the GitHub repository you want and simply click the ‘Fork’ button, creating a free copy for your use.\n\n\nOpen the given github repo → https://github.com/propardhu/resume-maker\n\n\n\n\nclick on Fork and create a new fork\n\n\n\nSection 3: Customizing Your Portfolio\n\n\nNavigating to the JSON File: In your new repository, locate the JSON file. This is where you’ll make your portfolio come to life.\n\n\n👇Go to the resumeData.json in pulic folder → public/resumeData.json\n\n\n\n\nhttps://github.com/propardhu/resume-maker/tree/main/public\n\n\n\nEditing the JSON File Online: GitHub allows you to edit this file directly on their platform. Click to edit, and start personalizing with your details. It’s free and straightforward.\n\n\nStart by modifying the default content to reflect your own profile. For a more efficient and user-friendly editing experience, consider copying the content into an online JSON editor. This approach allows for quicker and more precise adjustments tailored to your needs.\n\n\nparticles-bg\n\n\n👆 The links provided above offer a selection of diverse background options for your name, allowing you to choose the one that best suits your style.\n\n\nCommitting Changes: Save your updates with a commit, directly on GitHub — no local setup involved.\n\n\nImportant Caution: Please ensure that the JSON file remains valid after your edits. Additionally, any links that point to specific files should be located within the ‘public’ folder of the project. This ensures proper functioning and accessibility of your portfolio’s resources. Remember, a valid JSON structure and correctly placed links are crucial for the seamless performance of your portfolio.\n\n\nSection 4: Hosting on Netlify\n\n\nCreating a Netlify Account: Sign up with Netlify for free using your GitHub account.Connecting GitHub to Netlify: Easily link your GitHub repository to Netlify. Their free plan is perfect for getting your portfolio online.\n\n\nA Step-by-Step Guide: Deploying on Netlify\n\n\n👆 Here we have a detailed explanation for the setup.\n\n\nSection 5: Launching Your Portfolio\n\n\nDeploying the Project: With just a couple of clicks, deploy your portfolio on Netlify, completely free of charge.Custom Domain Configuration (Optional): Netlify offers free options to add a custom domain, making your portfolio stand out.\n\n\nConclusion\n\n\nYou’ve done it — your portfolio is now live, and it didn’t cost you anything! Remember, this is just the start. Your portfolio can evolve as your skills and experiences grow.\n\n\n\n\nPhoto by Joshua Harris on Unsplash\n\n\n\nThank you….!preview few outputs 🙂\n\n\n\nPardhu\n\n\nAkhilesh\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2023-07-06-image-processing-using-cnn.html",
    "href": "blog_posts/2023-07-06-image-processing-using-cnn.html",
    "title": "Image Processing using CNN",
    "section": "",
    "text": "click here to read this in medium\n\nConvolutional Neural Network\n\n\n\n\nmedium\n\n\n\nBasics →\n\n\n\n\nPhoto by Sebastian Bill on Unsplash\n\n\n\nWhat is an Image?\n\n\nAn image is nothing but an array of elements called pixels. A pixel is the smallest unit of a digital image or graphic that can be displayed and represented on a digital display device, which ranges between 0 and 255.So, image is nothing but an n * 2d Array with values ranging from 0 to 255.Note :- n depends on type of image, if the image is represented in RGB the n will be in 3.\n\n\n\n\nPhoto by Jon Tyson on Unsplash\n\n\n\nWe are using MNIST dataset each image is a 28X28 pixel square. Which means we will be having 1 * 28 * 28 resolution images in our dataset. Let’s get the dataset and display the image😃.\n\nimport tensorflow as tfimport numpy as npfrom matplotlib import pyplot as pltfrom tensorflow.keras import utils as np_utils(X_train,y_train),(X_test,y_test) = tf.keras.datasets.mnist.load_data()X_test = X_test.reshape(X_test.shape[0], 1,28,28).astype('float32')X_test = X_test/255y_test = np_utils.to_categorical(y_test)y_test = y_test/255first_image = np.array(X_test[0], dtype='float')pixels = first_image.reshape((28, 28))plt.imshow(pixels, cmap='gray')plt.show()\n\n\n\n\nIntroduction :-\n\n\nCNN contains three type of layers which are\n\n\nConvolutional Layer — Here we will be extracting the features present in the image. Example we can find all the horizontal lines present in the image using dot product of our horizontal matrix with the image matrix, then the resultant matrix will only contain the horizontal lines.\n\n\n\n\nhorizontal lines from the image source coding lane\n\n\n\n\n\nIllustration of Convolution Operation(source)\n\n\n\nPooling Layer — It is used to reduce the image size. By simply doing dot product for the image with a fixed slider.\n\n\n\n\nfrom coding lane\n\n\n\n\n\nfrom coding lane\n\n\n\n\n\nfrom coding lane\n\n\n\nFully-Connected layer — Here it flattens the pixels and learns to associate features by forming all the combinations of flatten objects.\n\n\n\n\nPhoto by Norbert Braun on Unsplash\n\n\n\nLet’s jump on the task\n\n\nwe have a dataset which contains digits from 0 to 9 in the form of images. Our task is to build a CNN model to predict the digit. So out CNN layers will be in this form.\n\n\nOutput Layer(10 outputs)Hidden Layer(128 neurons)Flatten LayerDropout Layer20%Max Pooling Layer2×2Convolutional Layer32 maps, 5×5Visible Layer1x28x28\n\n\n\nThe first hidden layer is a Convolutional layer called Convolution2D. It consists of 32 feature maps with a size of 5×5 and uses the rectifier activation function.\n\n\nThe next layer is a pooling layer called MaxPooling2D. It performs 2×2 pooling, which means it takes the maximum value from a 2×2 grid of values.\n\n\nA dropout layer follows, which helps with regularization. It randomly excludes 20% of the neurons in the layer during training to prevent overfitting.\n\n\nThe fifth layer is a flattened layer called Flatten. It converts the 2D matrix data from the previous layer into a 1D vector, allowing it to be processed by a fully connected layer.\n\n\nNext, there is a fully connected layer with 128 neurons and the rectifier activation function.\n\n\nFinally, the output layer consists of 10 neurons, representing the 10 classes in the classification task. It uses the softmax activation function to produce probability-like predictions for each class.\n\n\n\nCoding it:\n\nimport numpy as npfrom matplotlib import pyplot as pltfrom tensorflow.keras.utils import to_categoricalfrom keras.models import Sequentialfrom keras.layers import Densefrom tensorflow.keras import utils as np_utilsfrom keras.layers import Dropoutfrom keras.layers import Flattenfrom tensorflow.keras.layers import Conv2Dfrom tensorflow.keras.layers import MaxPooling2Dimport tensorflow as tfimport time#importing and preprocessing(X_train,y_train), (X_test, y_test)= tf.keras.datasets.mnist.load_data()X_train=X_train.reshape(X_train.shape[0], 1,28,28).astype('float32')X_test=X_test.reshape(X_test.shape[0], 1,28,28).astype('float32')X_train=X_train/255X_test=X_test/255y_train = np_utils.to_categorical(y_train)y_test= np_utils.to_categorical(y_test)num_classes=y_train.shape[1]print(num_classes)#prepare your modeldef cnn_model():    model=Sequential()    # Convolutional Layer 32 map 5X5 and input 1 * 28 * 28    model.add(Conv2D(32,5,5, padding='same',input_shape=(1,28,28), activation='relu'))    # Max Pooling Layer 2 X 2    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))    # Dropout Layer 20%    model.add(Dropout(0.2))    # Flatten Layer    model.add(Flatten())    # Hidden Layer 128 neurons    model.add(Dense(128, activation='relu'))    # Output Layer    model.add(Dense(num_classes, activation='softmax'))    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])    return modelt1 = time.time_ns()model=cnn_model()model.fit(X_train, y_train, validation_data=(X_test,y_test),epochs=10, batch_size=200, verbose=2)t2 = time.time_ns()score= model.evaluate(X_test, y_test, verbose=0)t3 = time.time_ns()train_time = t2-t1evaluavation_time = t3-t2print('The accuracy is: %.2f%%'%(score[1]))print(f'training time {train_time}, evaluvation time {evaluavation_time}')first_image = np.array(X_test[0], dtype='float')pixels = first_image.reshape((28, 28))plt.imshow(pixels, cmap='gray')plt.show()t4 = time.time_ns()test_input = first_image.reshape((-1, 1, 28, 28))k = model.predict(test_input).tolist()t5 = time.time_ns()print(f'predicted output : {k[0].index(max(k[0]))}')print(f'actual output : {y_test[0]}')print(f'prediction time {t5-t4}')\n\n\n\nPhoto by Ricardo Arce on Unsplash\n\n\n\nResults\n\n\nAccuracy — 97%Training run time — 7.2892 SecEvaluation run time — 0.186776 SecPrediction run time (for digit 7) — 0.033601 Sec\n\n\nComplete code is available in my GitHub (https://github.com/propardhu/Pandas_Play/blob/main/CNN_mnist.ipynb)\n\nhttps://medium.com/media/9602ed028d76e3f631dae05408c7e2cd/href\n\n\nPardhu Guttikonda - Medium\n\n\nPandas_Play/CNN_mnist.ipynb at main · propardhu/Pandas_Play\n\n\n\n\n\nPhoto by Priscilla Du Preez on Unsplash"
  },
  {
    "objectID": "blog_posts/2022-07-10-spring-boot-authentication-and-authorization.html",
    "href": "blog_posts/2022-07-10-spring-boot-authentication-and-authorization.html",
    "title": "Spring Boot Authentication and Authorization",
    "section": "",
    "text": "click here to read this in medium\n\nSpring security, JWT, Authorisations\n\n\n\n\nPhoto by Florian Berger on Unsplash\n\n\n\n🥷 What we do\n\n\nIn this article, We will be creating a Spring boot application to demonstrate Authentication and Authorization to users. For this Demo, we will be using MongoDB database. Also For this Authentication we will be using JWT Standard, and we will be using HS512 algorithm to encode the information.\n\n\n🎯Dependencies used :\n\n\nplease view at link . (https://github.com/propardhu/AuthDemoSpringBoot/blob/main/build.gradle)\n\n\n🧞‍♂️Steps To be followed\n\n\n\nCreate domain and repository for Both users and Authorities.\n\n\nPrepare JWT and Security Utilities.\n\n\nConfigure spring security and JWT Filters.\n\n\nmongock ChangeLog to add initial users to DataBase.\n\n\n\n\n\nPhoto by Zeynep Sümer on Unsplash\n\n\n\nDocument Structures of Both User and Authorities\n\n\nAuthority.java\n\n/** * An authority (a security role) used by Spring Security. */@Document(collection = \"authority\")public class Authority implements Serializable {    private static final long serialVersionUID = 1L;    @NotNull    @Size(max = 50)    @Id    private String name;    public String getName() {        return name;    }    public void setName(String name) {        this.name = name;    }    @Override    public boolean equals(Object o) {        if (this == o) {            return true;        }        if (!(o instanceof Authority)) {            return false;        }        return Objects.equals(name, ((Authority) o).name);    }    @Override    public int hashCode() {        return Objects.hashCode(name);    }    // prettier-ignore    @Override    public String toString() {        return \"Authority{\" +            \"name='\" + name + '\\'' +            \"}\";    }}\n\nUser.java\n\n/** * A user. */@org.springframework.data.mongodb.core.mapping.Document(collection = \"user\")public class User extends AbstractAuditingEntity implements Serializable {    private static final long serialVersionUID = 1L;    @Id    private String id;    @NotNull    @Pattern(regexp = Constants.LOGIN_REGEX)    @Size(min = 1, max = 50)    @Indexed    private String login;    @JsonIgnore    @NotNull    @Size(min = 60, max = 60)    private String password;    @Size(max = 50)    @Field(\"first_name\")    private String firstName;    @Size(max = 50)    @Field(\"last_name\")    private String lastName;    @Email    @Size(min = 5, max = 254)    @Indexed    private String email;    private boolean activated = false;    @Size(min = 2, max = 10)    @Field(\"lang_key\")    private String langKey;    @Size(max = 256)    @Field(\"image_url\")    private String imageUrl;    @Size(max = 20)    @Field(\"activation_key\")    @JsonIgnore    private String activationKey;    @Size(max = 20)    @Field(\"reset_key\")    @JsonIgnore    private String resetKey;    @Field(\"reset_date\")    private Instant resetDate = null;    @JsonIgnore    private Set&lt;Authority&gt; authorities = new HashSet&lt;&gt;();}\n\nUserRepository.java\n\n@Repositorypublic interface UserRepository extends MongoRepository&lt;User, String&gt; {    Optional&lt;User&gt; findOneByActivationKey(String activationKey);    List&lt;User&gt; findAllByActivatedIsFalseAndActivationKeyIsNotNullAndCreatedDateBefore(Instant dateTime);    Optional&lt;User&gt; findOneByResetKey(String resetKey);    Optional&lt;User&gt; findOneByEmailIgnoreCase(String email);    Optional&lt;User&gt; findOneByLogin(String login);    Page&lt;User&gt; findAllByIdNotNullAndActivatedIsTrue(Pageable pageable);}\n\nAuthorityRepository.java\n\n/** * Spring Data MongoDB repository for the {@link Authority} entity. */public interface AuthorityRepository extends MongoRepository&lt;Authority, String&gt; {}\n\nAuthoritiesConstants.java\n\npublic final class AuthoritiesConstants {    public static final String ADMIN = \"ROLE_ADMIN\";    public static final String USER = \"ROLE_USER\";    public static final String ANONYMOUS = \"ROLE_ANONYMOUS\";    private AuthoritiesConstants() {}}\n\nJWT Things\n\n\n👉 JWT working Flow:-\n\n\n\nJSON Web Token(JWT) is an open standard used to share security information between two parties like client and server. It follows one particular cryptographic algorithm to encrypt and decrypt the JSON Objects. Algorithms like Hash 512,Hash 256, RS256 etc.\n\n\nWhen a user registers in an application, user details are sent to the server. While saving the user details. We will ensure to encrypt the password while saving into the database.(BCryptPasswordEncoder)\n\n\nWhen a user logs in to the application, details like username and password will be sent to the server. There we will be verifying the password with encrypted password. If matches, we will be creating an JWT token and sent it as a response.\n\n\nAfter getting the JWT token, we need to append the token in the header of HTTP request (For all secured endpoints, we need to follow the same).\n\n\nThe JWT token contains three parts (HEADER, PAYLOAD)are Base64-URL encoded JSON and Cryptographic Signature.Note:- We need a secret key to encrypt and decrypt data.\n\n\nFor Authorization, we will be adding the roles of the user to the token itself.\n\n\n\n\n\nPhoto by Georg Bommeli on Unsplash\n\n\n\nTokenProvider.javaHere we will be writing the methods to createTokens, getAuthentications from token and validate token.Replace “KEY” with secretKey.\n\n@Componentpublic class TokenProvider {    private final Logger log = LoggerFactory.getLogger(TokenProvider.class);    private static final String AUTHORITIES_KEY = \"auth\";    private final Key key;    private final JwtParser jwtParser;    private final long tokenValidityInMilliseconds;    private final long tokenValidityInMillisecondsForRememberMe;    public TokenProvider() {        byte[] keyBytes;        String secret = \"KEY\";        if (!ObjectUtils.isEmpty(secret)) {            log.debug(\"Using a Base64-encoded JWT secret key\");            keyBytes = Decoders.BASE64.decode(secret);        } else {            log.warn(                \"Warning: the JWT key used is not Base64-encoded. \" +                \"We recommend using the `jhipster.security.authentication.jwt.base64-secret` key for optimum security.\"            );            secret = \"YWQzMmJiZjgwMDliY2M4NWE0ZjVkOWUxZmRjYTcwMDc2OTZkN2Y5MzQ3ODQ4N2M2YmExNTVmNDFjMDdhZGUzZDRmZDE2OGFkMTc1NmE4MWVmYTIxZDI3YWIzZTNhNzQ1YjNhMzE1ZGVmMWRhNWQxZGFhN2I3NjQzMWRkNjczODY=\";            keyBytes = secret.getBytes(StandardCharsets.UTF_8);        }        key = Keys.hmacShaKeyFor(keyBytes);        jwtParser = Jwts.parserBuilder().setSigningKey(key).build();        this.tokenValidityInMilliseconds = 1000 * 700;        this.tokenValidityInMillisecondsForRememberMe = 1000 * 700;    }    public String createToken(Authentication authentication, boolean rememberMe) {        String authorities = authentication.getAuthorities().stream().map(GrantedAuthority::getAuthority).collect(Collectors.joining(\",\"));        long now = (new Date()).getTime();        Date validity;        if (rememberMe) {            validity = new Date(now + this.tokenValidityInMillisecondsForRememberMe);        } else {            validity = new Date(now + this.tokenValidityInMilliseconds);        }        return Jwts            .builder()            .setSubject(authentication.getName())            .claim(AUTHORITIES_KEY, authorities)            .signWith(key, SignatureAlgorithm.HS512)            .setExpiration(validity)            .compact();    }    public Authentication getAuthentication(String token) {        Claims claims = jwtParser.parseClaimsJws(token).getBody();        Collection&lt;? extends GrantedAuthority&gt; authorities = Arrays            .stream(claims.get(AUTHORITIES_KEY).toString().split(\",\"))            .filter(auth -&gt; !auth.trim().isEmpty())            .map(SimpleGrantedAuthority::new)            .collect(Collectors.toList());        User principal = new User(claims.getSubject(), \"\", authorities);        return new UsernamePasswordAuthenticationToken(principal, token, authorities);    }    public boolean validateToken(String authToken) {        try {            jwtParser.parseClaimsJws(authToken);            return true;        } catch (JwtException | IllegalArgumentException e) {            log.info(\"Invalid JWT token.\");            log.trace(\"Invalid JWT token trace.\", e);        }        return false;    }}\n\nJWTConfigurer.javaNow We need to add JWTFilter with tokenProvider to the HttpSecurity, That can be overwritten by extending SecurityConfigurerAdapter&lt;DefaultSecurityFilterChain, HttpSecurity&gt;.\n\npublic class JWTConfigurer extends SecurityConfigurerAdapter&lt;DefaultSecurityFilterChain, HttpSecurity&gt; {    private final TokenProvider tokenProvider;    public JWTConfigurer(TokenProvider tokenProvider) {        this.tokenProvider = tokenProvider;    }    @Override    public void configure(HttpSecurity http) {        JWTFilter customFilter = new JWTFilter(tokenProvider);        http.addFilterBefore(customFilter, UsernamePasswordAuthenticationFilter.class);    }}\n\nJWTFilter.javaThis class will be extending the GenericFilterBean class and we can add Filter by overriding doFilter method. So here we will be validating all the request with bearer token. if the request do not have it can access only public API’s.\n\npublic class JWTFilter extends GenericFilterBean {    public static final String AUTHORIZATION_HEADER = \"Authorization\";    private final TokenProvider tokenProvider;    public JWTFilter(TokenProvider tokenProvider) {        this.tokenProvider = tokenProvider;    }    @Override    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)        throws IOException, ServletException {        HttpServletRequest httpServletRequest = (HttpServletRequest) servletRequest;        String jwt = resolveToken(httpServletRequest);        if (StringUtils.hasText(jwt) && this.tokenProvider.validateToken(jwt)) {            Authentication authentication = this.tokenProvider.getAuthentication(jwt);            SecurityContextHolder.getContext().setAuthentication(authentication);        }        filterChain.doFilter(servletRequest, servletResponse);    }    private String resolveToken(HttpServletRequest request) {        String bearerToken = request.getHeader(AUTHORIZATION_HEADER);        if (StringUtils.hasText(bearerToken) && bearerToken.startsWith(\"Bearer \")) {            return bearerToken.substring(7);        }        return null;    }}\n\nService which provides user details from DataBase need to be declared as component to avoid dependency cycle in our project.\n\n/** * Authenticate a user from the database. */@Component(\"userDetailsService\")public class DomainUserDetailsService implements UserDetailsService {    private final Logger log = LoggerFactory.getLogger(DomainUserDetailsService.class);    private final UserRepository userRepository;    public DomainUserDetailsService(UserRepository userRepository) {        this.userRepository = userRepository;    }    @Override    public UserDetails loadUserByUsername(final String login) {        log.debug(\"Authenticating {}\", login);        if (new EmailValidator().isValid(login, null)) {            return userRepository                .findOneByEmailIgnoreCase(login)                .map(user -&gt; createSpringSecurityUser(login, user))                .orElseThrow(() -&gt; new UsernameNotFoundException(\"User with email \" + login + \" was not found in the database\"));        }        String lowercaseLogin = login.toLowerCase(Locale.ENGLISH);        return userRepository            .findOneByLogin(lowercaseLogin)            .map(user -&gt; createSpringSecurityUser(lowercaseLogin, user))            .orElseThrow(() -&gt; new UsernameNotFoundException(\"User \" + lowercaseLogin + \" was not found in the database\"));    }    private org.springframework.security.core.userdetails.User createSpringSecurityUser(String lowercaseLogin, User user) {        if (!user.isActivated()) {            throw new UserNotActivatedException(\"User \" + lowercaseLogin + \" was not activated\");        }        List&lt;GrantedAuthority&gt; grantedAuthorities = user            .getAuthorities()            .stream()            .map(authority -&gt; new SimpleGrantedAuthority(authority.getName()))            .collect(Collectors.toList());        return new org.springframework.security.core.userdetails.User(user.getLogin(), user.getPassword(), grantedAuthorities);    }}\n\nSecurityUtils.javaHere we will be writing methods related to current user login like getCurrentUserName etc.\n\n/** * Utility class for Spring Security. */public final class SecurityUtils {    private SecurityUtils() {}    /**     * Get the login of the current user.     *     * @return the login of the current user.     */    public static Optional&lt;String&gt; getCurrentUserLogin() {        SecurityContext securityContext = SecurityContextHolder.getContext();        return Optional.ofNullable(extractPrincipal(securityContext.getAuthentication()));    }    private static String extractPrincipal(Authentication authentication) {        if (authentication == null) {            return null;        } else if (authentication.getPrincipal() instanceof UserDetails) {            UserDetails springSecurityUser = (UserDetails) authentication.getPrincipal();            return springSecurityUser.getUsername();        } else if (authentication.getPrincipal() instanceof String) {            return (String) authentication.getPrincipal();        }        return null;    }    /**     * Get the JWT of the current user.     *     * @return the JWT of the current user.     */    public static Optional&lt;String&gt; getCurrentUserJWT() {        SecurityContext securityContext = SecurityContextHolder.getContext();        return Optional            .ofNullable(securityContext.getAuthentication())            .filter(authentication -&gt; authentication.getCredentials() instanceof String)            .map(authentication -&gt; (String) authentication.getCredentials());    }    /**     * Check if a user is authenticated.     *     * @return true if the user is authenticated, false otherwise.     */    public static boolean isAuthenticated() {        Authentication authentication = SecurityContextHolder.getContext().getAuthentication();        return authentication != null && getAuthorities(authentication).noneMatch(AuthoritiesConstants.ANONYMOUS::equals);    }    /**     * Checks if the current user has any of the authorities.     *     * @param authorities the authorities to check.     * @return true if the current user has any of the authorities, false otherwise.     */    public static boolean hasCurrentUserAnyOfAuthorities(String... authorities) {        Authentication authentication = SecurityContextHolder.getContext().getAuthentication();        return (            authentication != null && getAuthorities(authentication).anyMatch(authority -&gt; Arrays.asList(authorities).contains(authority))        );    }    /**     * Checks if the current user has none of the authorities.     *     * @param authorities the authorities to check.     * @return true if the current user has none of the authorities, false otherwise.     */    public static boolean hasCurrentUserNoneOfAuthorities(String... authorities) {        return !hasCurrentUserAnyOfAuthorities(authorities);    }    /**     * Checks if the current user has a specific authority.     *     * @param authority the authority to check.     * @return true if the current user has the authority, false otherwise.     */    public static boolean hasCurrentUserThisAuthority(String authority) {        return hasCurrentUserAnyOfAuthorities(authority);    }    private static Stream&lt;String&gt; getAuthorities(Authentication authentication) {        return authentication.getAuthorities().stream().map(GrantedAuthority::getAuthority);    }}\n\n\n\nPhoto by Philipp Katzenberger on Unsplash\n\n\n\nSecurity Configurations\n\n\nSecurityConfiguration.javaHere we will be saying what kind of api’s need to be permitted as public api’s.\n\n@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true)@Import(SecurityProblemSupport.class)public class SecurityConfiguration extends WebSecurityConfigurerAdapter {    private final TokenProvider tokenProvider;    private final CorsFilter corsFilter;    private final SecurityProblemSupport problemSupport;    public SecurityConfiguration(        TokenProvider tokenProvider,        CorsFilter corsFilter,        SecurityProblemSupport problemSupport    ) {        this.tokenProvider = tokenProvider;        this.corsFilter = corsFilter;        this.problemSupport = problemSupport;    }    @Bean    public PasswordEncoder passwordEncoder() {        return new BCryptPasswordEncoder();    }    @Override    public void configure(WebSecurity web) {        web.ignoring().antMatchers(HttpMethod.OPTIONS, \"/**\").antMatchers(\"/swagger-ui/**\").antMatchers(\"/test/**\");    }    @Override    public void configure(HttpSecurity http) throws Exception {        // @formatter:off        http            .csrf()            .disable()            .addFilterBefore(corsFilter, UsernamePasswordAuthenticationFilter.class)            .exceptionHandling()                .authenticationEntryPoint(problemSupport)                .accessDeniedHandler(problemSupport)        .and()            .headers()            .contentSecurityPolicy(\"default-src 'self'; frame-src 'self' data:; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://storage.googleapis.com; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self' data:\")        .and()            .referrerPolicy(ReferrerPolicyHeaderWriter.ReferrerPolicy.STRICT_ORIGIN_WHEN_CROSS_ORIGIN)        .and()            .permissionsPolicy().policy(\"camera=(), fullscreen=(self), geolocation=(), gyroscope=(), magnetometer=(), microphone=(), midi=(), payment=(), sync-xhr=()\")        .and()            .frameOptions()            .deny()        .and()            .sessionManagement()            .sessionCreationPolicy(SessionCreationPolicy.STATELESS)        .and()            .authorizeRequests()            .antMatchers(\"/api/authenticate\").permitAll()            .antMatchers(\"/api/register\").permitAll()            .antMatchers(\"/api/activate\").permitAll()            .antMatchers(\"/api/account/reset-password/init\").permitAll()            .antMatchers(\"/api/account/reset-password/finish\").permitAll()            .antMatchers(\"/api/admin/**\").hasAuthority(AuthoritiesConstants.ADMIN)            .antMatchers(\"/api/**\").authenticated()            .antMatchers(\"/management/health\").permitAll()            .antMatchers(\"/management/health/**\").permitAll()            .antMatchers(\"/management/info\").permitAll()            .antMatchers(\"/management/prometheus\").permitAll()            .antMatchers(\"/management/**\").hasAuthority(AuthoritiesConstants.ADMIN)        .and()            .httpBasic()        .and()            .apply(securityConfigurerAdapter());        // @formatter:on    }    private JWTConfigurer securityConfigurerAdapter() {        return new JWTConfigurer(tokenProvider);    }}\n\nWebConfigure.javaAllowed domains needs be to added here to avoid COR’s related issues\n\n/** * Configuration of web application with Servlet 3.0 APIs. */@Configurationpublic class WebConfigurer implements ServletContextInitializer {    private final Logger log = LoggerFactory.getLogger(WebConfigurer.class);    private final Environment env;    public WebConfigurer(Environment env) {        this.env = env;    }    @Override    public void onStartup(ServletContext servletContext) throws ServletException {        if (env.getActiveProfiles().length != 0) {            log.info(\"Web application configuration, using profiles: {}\", (Object[]) env.getActiveProfiles());        }        log.info(\"Web application fully configured\");    }    @Bean    public CorsFilter corsFilter() {        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();        CorsConfiguration config = new CorsConfiguration();        List&lt;String&gt; list = new ArrayList&lt;&gt;();        list.add(\"*\");        config.setAllowedOriginPatterns(list);        if (!CollectionUtils.isEmpty(config.getAllowedOrigins()) || !CollectionUtils.isEmpty(config.getAllowedOriginPatterns())) {            log.debug(\"Registering CORS filter\");            source.registerCorsConfiguration(\"/api/**\", config);            source.registerCorsConfiguration(\"/management/**\", config);            source.registerCorsConfiguration(\"/v2/api-docs\", config);            source.registerCorsConfiguration(\"/v3/api-docs\", config);            source.registerCorsConfiguration(\"/swagger-resources\", config);            source.registerCorsConfiguration(\"/swagger-ui/**\", config);        }        return new CorsFilter(source);    }}\n\n\n\nPhoto by benjamin lehman on Unsplash\n\n\n\nMongock ChangeLog\n\n\nWe will be using mongock to add default user details to database like admin.\n\n\nIn application.properties we need to give the path of the class which contains ChangeLog annotation.\n\nspring.data.mongodb.uri=mongodb://localhost:27017/AuthDemomongock.change-logs-scan-package=com.pardhu.authdemo.config.InitialSetupMigration\n\nInitialSetupMigration.java\n\n/** * Creates the initial database setup. */@ChangeLog(order = \"001\")public class InitialSetupMigration {    @ChangeSet(order = \"01\", author = \"initiator\", id = \"01-addAuthorities\")    public void addAuthorities(MongockTemplate mongoTemplate) {        Authority adminAuthority = new Authority();        adminAuthority.setName(AuthoritiesConstants.ADMIN);        Authority userAuthority = new Authority();        userAuthority.setName(AuthoritiesConstants.USER);        mongoTemplate.save(adminAuthority);        mongoTemplate.save(userAuthority);    }    @ChangeSet(order = \"02\", author = \"initiator\", id = \"02-addUsers\")    public void addUsers(MongockTemplate mongoTemplate) {        Authority adminAuthority = new Authority();        adminAuthority.setName(AuthoritiesConstants.ADMIN);        Authority userAuthority = new Authority();        userAuthority.setName(AuthoritiesConstants.USER);        User adminUser = new User();        adminUser.setId(\"user-1\");        adminUser.setLogin(\"admin\");        adminUser.setPassword(\"$2a$10$gSAhZrxMllrbgj/kkK9UceBPpChGWJA7SYIb1Mqo.n5aNLq1/oRrC\");        adminUser.setFirstName(\"admin\");        adminUser.setLastName(\"Administrator\");        adminUser.setEmail(\"admin@localhost\");        adminUser.setActivated(true);        adminUser.setLangKey(\"en\");        adminUser.setCreatedBy(Constants.SYSTEM);        adminUser.setCreatedDate(Instant.now());        adminUser.getAuthorities().add(adminAuthority);        adminUser.getAuthorities().add(userAuthority);        mongoTemplate.save(adminUser);        User userUser = new User();        userUser.setId(\"user-2\");        userUser.setLogin(\"user\");        userUser.setPassword(\"$2a$10$VEjxo0jq2YG9Rbk2HmX9S.k1uZBGYUHdUcid3g/vfiEl7lwWgOH/K\");        userUser.setFirstName(\"\");        userUser.setLastName(\"User\");        userUser.setEmail(\"user@localhost\");        userUser.setActivated(true);        userUser.setLangKey(\"en\");        userUser.setCreatedBy(Constants.SYSTEM);        userUser.setCreatedDate(Instant.now());        userUser.getAuthorities().add(userAuthority);        mongoTemplate.save(userUser);    }}\n\nNow we have two Authorities. Admin and User.While writing an api in controller itself we can annotate like this api can be accessed by admin only using annotations →@PreAuthorize(“hasAuthority(”” + AuthoritiesConstants.ADMIN + “”)”)@PostAuthorize(“hasAuthority(”” + AuthoritiesConstants.ADMIN + “”)”)\n\n\nComplete working git repo is available at GitHub . Also we wrote few login and register API’s.\n\n\nThank you….\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2023-03-05-binary-tree-data-structure.html",
    "href": "blog_posts/2023-03-05-binary-tree-data-structure.html",
    "title": "Binary Tree Data Structure",
    "section": "",
    "text": "click here to read this in medium\n\nBinary Tree Traversals and problem solving\n\n\n\n\nPhoto by JJ Ying on Unsplash\n\n\n\n💡 Common terms :-\n\n\n\n\nfrom upGrad\n\n\n\nIn this article we will be Discussing different tree traversals and problem solving based on these tree traversals.Note: All the code is in JAVA.\n\n\n\n\nPhoto by N. on Unsplash\n\n\n\n🌴 Tree Traversals : (Depth First Traversals)\n\n\n\nIn-Order\n\n\nPre-Order\n\n\nPost-Order\n\n\n\nThe goal of these traversals is to visit all the nodes in the binary tree.\n\n\n\n\nFrom GeeksforGeeks\n\n\n\nIn-Order Traversal :-\n\n\nIn this In-order →1. First visit all nodes on the left 2. visit present node 3. Then visit all nodes on the right\n\nvoid inorder(TreeNode root) {        if(root==null){          return;        }        inorder(root.left);        System.out.println(root.val);        inorder(root.right);}\n\nLeetCode submission → https://leetcode.com/problems/binary-tree-inorder-traversal/submissions/679456795/\n\n\nPre-Order Traversal:-\n\n\nHere we follow →1. First visit present node2. visit all nodes on the left3. Then visit all nodes on the right\n\nvoid preorder(TreeNode r){        if(r==null){            return;        }        System.out.println(r.val);        preorder(r.left);        preorder(r.right);    }\n\nLeetCode submission → https://leetcode.com/problems/binary-tree-preorder-traversal/submissions/908748627/\n\n\nPost-Order Traversal:-\n\n\nHere we follow →1. First visit all nodes on the left 2. Then visit all nodes on the right3. Visit present node\n\nvoid postOrder(TreeNode r) {        if(r ==null) {            return;        }        postOrder(r.left);        postOrder(r.right);        System.out.println(r.val);    }\n\nLeetCode submission → https://leetcode.com/problems/binary-tree-postorder-traversal/submissions/908750442/\n\n\n🛠 Level Order Traversal : (Breadth First Traversal)\n\n\nHere the goal is to print the tree nodes level by level. My Implementation\n\nclass Solution {    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();    public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) {        solve(root,0);        return res;    }    public void solve(TreeNode n,int level){        if(n==null)return ;        if(res.size()&gt;level){            res.get(level).add(n.val);        }else{            List&lt;Integer&gt; t = new ArrayList&lt;&gt;();            t.add(n.val);            res.add(t);        }        solve(n.left,level+1);        solve(n.right,level+1);    }}\n\nLeetCode submission → https://leetcode.com/problems/binary-tree-level-order-traversal/submissions/677053619/\n\n\nBut BFS says to maintain the queue where we first add root node and loop by pop the node and add the children to the queue.Which also gives the similar result with same runtime.\n\n\n🥷 Example problem 1\n\n\nSum Root to Leaf Numbers - LeetCode\n\n\nHere we need to find a way to get all possible numbers formed by traversing from the root node to each leaf node. Then sum it up. So after observing the problem statement, we can get an idea that we need to use preorder Traversal. But the Question is How we can identify the different paths from root to leaf node? So I got the idea to add an edge case to the preorder traversal saying hey if the present node leaf node here the code for it.\n\nclass Solution {    int sum  = 0;    public int sumNumbers(TreeNode root) {        preorder(root,new StringBuilder());        return sum;    }    public void preorder(TreeNode node, StringBuilder sb){        if (node == null) return;        sb.append(node.val);        if (node.left == null && node.right == null) {            sum += Integer.parseInt(sb.toString());        }        preorder(node.left, sb);        preorder(node.right, sb);        sb.deleteCharAt(sb.length() - 1);    }}// https://leetcode.com/problems/sum-root-to-leaf-numbers/submissions/908758869/\n\n🚀 Example problem 2\n\n\nBinary Tree Maximum Path Sum - LeetCode\n\n\nThis is also a very interesting problem. Where we need to find the Path where we can get the maximum Sum by adding the node values. In these case where we need to see all the nodes from the bottom of the tree. We have to go with postOrder kind of approach to solve this problem. Here is my solution.\n\nclass Solution {    int final_max = Integer.MIN_VALUE;    public int maxPathSum(TreeNode root) {        solve(root);        return final_max;    }    public int solve(TreeNode root){        if(root==null){return 0;}        int leftMax = solve(root.left);        int rightMax = solve(root.right);        int send_top = Math.max(Math.max(leftMax,rightMax)+root.val,root.val);        int comMax = Math.max(leftMax+rightMax+root.val,send_top);        final_max = Math.max(final_max,comMax);        return send_top;    }}// https://leetcode.com/problems/binary-tree-maximum-path-sum/submissions/909178204/\n\nThank you…!\n\n\n\nPardhu Guttikonda - Medium\n\n\npropardhu - LeetCode Profile"
  },
  {
    "objectID": "blog_posts/2022-10-07-cucumber-with-selenium-automation.html",
    "href": "blog_posts/2022-10-07-cucumber-with-selenium-automation.html",
    "title": "Cucumber with Selenium Automation",
    "section": "",
    "text": "click here to read this in medium\n\nProject setup for cucumber Selenium automation using page object modal\n\n\n\n\nPhoto by Kaleidico on Unsplash\n\n\n\nSteps to be followed →\n\n\n\nCreate a maven project (I will be using IntelliJ).🛠\n\n\nAdd the dependences.🧞‍♂️\n\n\nCreate the Runner JAVA file.💡\n\n\nCreate as per the Runner file structure.⏳\n\n\nRun tests using feature files ✅\n\n\n\nCreate a maven project in IntelliJ without any dependencies in it\n\n\n\nJust provide the project name and location to be stored in the process of creation maven project.\n\n\n\n\n\nPhoto by Jeremy Bezanger on Unsplash\n\n\n\nAdding Dependences to pom.xml → Given pom.xml below\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  &lt;groupId&gt;org.example&lt;/groupId&gt;  &lt;artifactId&gt;amazon-automation&lt;/artifactId&gt;  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  &lt;properties&gt;    &lt;maven.compiler.source&gt;16&lt;/maven.compiler.source&gt;    &lt;maven.compiler.target&gt;16&lt;/maven.compiler.target&gt;  &lt;/properties&gt;  &lt;dependencies&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.seleniumhq.selenium&lt;/groupId&gt;      &lt;artifactId&gt;selenium-java&lt;/artifactId&gt;      &lt;version&gt;4.3.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;io.cucumber&lt;/groupId&gt;      &lt;artifactId&gt;cucumber-gherkin&lt;/artifactId&gt;      &lt;version&gt;7.6.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.testng&lt;/groupId&gt;      &lt;artifactId&gt;testng&lt;/artifactId&gt;      &lt;version&gt;6.14.3&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;io.cucumber&lt;/groupId&gt;      &lt;artifactId&gt;cucumber-testng&lt;/artifactId&gt;      &lt;version&gt;7.6.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.seleniumhq.selenium&lt;/groupId&gt;      &lt;artifactId&gt;selenium-chrome-driver&lt;/artifactId&gt;      &lt;version&gt;4.3.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;io.cucumber&lt;/groupId&gt;      &lt;artifactId&gt;cucumber-gherkin&lt;/artifactId&gt;      &lt;version&gt;7.6.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;io.cucumber&lt;/groupId&gt;      &lt;artifactId&gt;cucumber-java&lt;/artifactId&gt;      &lt;version&gt;7.6.0&lt;/version&gt;    &lt;/dependency&gt;  &lt;/dependencies&gt;&lt;/project&gt;\n\nAs per the given pom.xml file add the dependencies.\n\n\nAdd Runner.JAVA to the project →\n\n\nRunner.java\n\n@CucumberOptions(    features = \"src/test/resources/features\",    glue = \"StepDefinitions\",    plugin = {        \"pretty\",        \"html:target/cucumber-reports/cucumber-pretty\",        \"json:target/cucumber-reports/CucumberTestReport.json\",        \"timeline:target/test-output-thread/\"    })public class Runner extends AbstractTestNGCucumberTests {  @Override  @DataProvider(parallel = true)  public Object[][] scenarios() {    return super.scenarios();  }  @BeforeSuite  public void beforeSuite() {    System.out.println(\"================ BEFORE SUITE==========\");  }  @AfterSuite  public void afterSuite() {    System.out.println(\"================ AFTER SUITE ==========\");  }}\n\n\nIn the above file we need to specify the path there the feature files are located in the project.(src/test/resources/features)\n\n\nAlso we have to mention the package name there the steps will be writen in the project.(StepDefinitions)\n\n\n\nCreate page object modals →\n\n\n\nMake BasePage class to place common methods which can be used to all the page classes.\n\n\npublic class BasePage {  private static WebDriver driver;  public static final int TIMEOUT_PERIOD_LONG = 30;  public BasePage(WebDriver driver) {    this.driver = driver;  }  public WebElement waitForElement(By element, long timeout) {    WebElement myElement = null;    try {      myElement = new WebDriverWait(driver, Duration.ofSeconds(timeout)).until(ExpectedConditions.visibilityOfElementLocated(element));    } catch (TimeoutException toe) {      System.out.println(toe);    } finally {      if (myElement == null) {        String str = \"Unable to find the WebElement in the web page by using its locator\";        System.out.println(str);      }    }    return myElement;  }  public void waitForElementToBeVisible(ById element){    WebElement myElement = new WebDriverWait(driver, Duration.ofSeconds(5)).until(ExpectedConditions.visibilityOfElementLocated(element));    WebDriverWait wait= new WebDriverWait(driver,Duration.ofSeconds(5));    wait.until(ExpectedConditions.visibilityOf(myElement));  }  public void waitForElementToBeVisible(ByXPath element){    WebElement myElement = new WebDriverWait(driver, Duration.ofSeconds(5)).until(ExpectedConditions.visibilityOfElementLocated(element));    WebDriverWait wait= new WebDriverWait(driver,Duration.ofSeconds(5));    wait.until(ExpectedConditions.visibilityOf(myElement));  }}\n\n\nCreating page class like shown below. all the page classes will be extending the BasePage class.\n\n\npublic class HomePage extends BasePage {  public HomePage(WebDriver driver) {    super(driver);    PageFactory.initElements(driver, this);  }  public final ById searchInput = new ById(\"twotabsearchtextbox\");  public WebElement getSearchInput() {    return waitForElement(searchInput,30);  }  public void waitTillSearchVisible() {    waitForElementToBeVisible(searchInput);  }}\n\nSearchResultPage.class\n\npublic class SearchResultPage extends BasePage {\npublic SearchResultPage(WebDriver driver) {        super(driver);        PageFactory.initElements(driver, this);    }\npublic final ById logoBtn = new ById(\"nav-logo-sprites\");\npublic final ByXPath item = new ByXPath(\"/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[4]/div/div/div/div/div[2]/div[2]/h2/a\");\npublic WebElement getItem() {        return waitForElement(item, 30);    }\npublic WebElement getLogoBtn() {        return waitForElement(logoBtn, 30);    }\npublic void waitTillLogoVisible() {        waitForElementToBeVisible(logoBtn);    }}\n\nNow we need to create a package stepdefinition and write all the steps which will be used in feature file.\n\n\nHooks.java\n\npublic class Hooks {    public static WebDriver driver;\n@Before    public void OpenDriver() {        System.setProperty(\"webdriver.chrome.driver\", \"src/test/resources/drivers/mac/chromedriver\");        driver = new ChromeDriver();    }\n@After    public void closeDriver() {        driver.close();    }}\n\nHomePageSteps.java\n\npublic class HomePageSteps {\nprivate final HomePage homePage;\npublic HomePageSteps() {        this.homePage = PageObjectManager.pageFactory().getHomePage(Hooks.driver);    }\n@Given(\"I'm on amazon\")    public void onAmazon() {        Hooks.driver.get(\"https://www.amazon.com/\");        this.homePage.waitTillSearchVisible();    }\n@When(\"I select Search for {string}\")    public void enterSearch(String enterText) {        WebElement searchInput = this.homePage.getSearchInput();        searchInput.clear();        searchInput.sendKeys(enterText);        searchInput.sendKeys(Keys.ENTER);    }}\n\nSearchPageSteps.java\n\npublic class SearchPageSteps {    public final SearchResultPage searchResultPage;\npublic SearchPageSteps() {        this.searchResultPage = PageObjectManager.pageFactory().getSearchResultPage(Hooks.driver);    }\n@Then(\"I'm on result page\")    public void onResultPage() {        this.searchResultPage.waitTillLogoVisible();    }\n@And(\"I click on item\")    public void clickOnItem() throws InterruptedException {        WebElement btn = this.searchResultPage.getItem();        btn.click();        Hooks.driver.wait(300);    }}\n\nFeatures file\n\nFeature: Search item Scenario: Search for given item   Given I'm on amazon   When I select Search for \"jackets\"   Then I'm on result page     And I click on item\n\nNow according to the statements in feature file Steps will be executed.\n\n\ncomplete code is available at https://github.com/propardhu/cucumber-selenium …!"
  },
  {
    "objectID": "publications/PhysiologicalSignalCompression.html",
    "href": "publications/PhysiologicalSignalCompression.html",
    "title": "Real-Time Diagnostic Integrity Meets Efficiency: A Novel Platform-Agnostic Architecture for Physiological Signal Compression",
    "section": "",
    "text": "IEEE BSN 2024\nHead-based signals such as EEG, EMG, EOG, and ECG collected by wearable systems will play a pivotal role in clinicaldiagnosis, monitoring, and treatment of important brain disorder diseases. However, the real-time transmission of thesignificant corpus physiological signals over extended periods consumes substantial power and time, limiting the viability of battery-dependent physiological monitoring wearables.This paper presents a novel deep-learning framework employing a variational autoencoder (VAE) for physiologicalsignal compression to reduce wearables’ computational complexity and energy consumption. Our approach achieves animpressive compression ratio of 1:293 specifically for spectrogram data, surpassing state-of-the-art compression techniques such as JPEG2000, H.264, Direct Cosine Transform(DCT), and Huffman Encoding, which do not excel in handling physiological signals. We validate the efficacy of thecompressed algorithms using collected physiological signalsfrom real patients in the Hospital and deploy the solutionon commonly used embedded AI chips (i.e., ARM Cortex V8and Jetson Nano). The proposed framework achieves a 91%seizure detection accuracy using XGBoost, confirming theapproach’s reliability, practicality, and scalability. arxiv link"
  },
  {
    "objectID": "publications/AdversarialAttack.html",
    "href": "publications/AdversarialAttack.html",
    "title": "Demonstration of an Adversarial Attack Against a Multimodal Vision Language Model for Pathology Imaging",
    "section": "",
    "text": "IEEE ISBI 2024\nIn the context of medical artificial intelligence, this study explores the vulnerabilities of the Pathology Language-Image Pretraining (PLIP) model, a Vision Language Foundation model, under targeted attacks. Leveraging the Kather Colon dataset with 7,180 H&E images across nine tissue types, our investigation employs Projected Gradient Descent (PGD) adversarial perturbation attacks to induce misclassifications intentionally. The outcomes reveal a 100% success rate in manipulating PLIP’s predictions, underscoring its susceptibility to adversarial perturbations. The qualitative analysis of adversarial examples delves into the interpretability challenges, shedding light on nuanced changes in predictions induced by adversarial manipulations. These findings contribute crucial insights into the interpretability, domain adaptation, and trustworthiness of Vision Language Models in medical imaging. The study emphasizes the pressing need for robust defenses to ensure the reliability of AI models. The source codes for this experiment can be found at https://github.com/jaiprakash1824/VLM_Adv_Attack. arxiv link"
  },
  {
    "objectID": "pubs.html",
    "href": "pubs.html",
    "title": "Publications",
    "section": "",
    "text": "Real-Time Diagnostic Integrity Meets Efficiency: A Novel Platform-Agnostic Architecture for Physiological Signal Compression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpatialVisVR:An Immersive, Multiplexed Medical Image Viewer With Contextual Similar-Patient Search\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDemonstration of an Adversarial Attack Against a Multimodal Vision Language Model for Pathology Imaging\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  }
]