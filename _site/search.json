[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Building an Advanced Image Search System with Machine Learning and ElasticSearch\n\n\n6 min\n\n\n\ncomputer-vision\n\n\n\n\n\n\n\nMay 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrad-CAM Visualisation of ResNet-50â€™s Decision Pathways\n\n\n7 min\n\n\n\ngrad-cam\n\n\n\n\n\n\n\nMay 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimplifying Kafka: Effortless Stream Processing with Docker\n\n\n4 min\n\n\n\nstreaming\n\n\n\n\n\n\n\nFeb 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFree & Easy Portfolio Launch: Customize and Host with GitHub and Netlify\n\n\n3 min\n\n\n\nportfolio\n\n\n\n\n\n\n\nNov 19, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNetwork Checklist for Unity VR Apps\n\n\n3 min\n\n\n\nunity\n\n\n\n\n\n\n\nOct 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage Processing using CNN\n\n\n5 min\n\n\n\nconvolutional-neural-net\n\n\n\n\n\n\n\nJul 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinary Tree Data Structure\n\n\n6 min\n\n\n\ngraph-traversal\n\n\n\n\n\n\n\nMar 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpring Data JPA\n\n\n4 min\n\n\n\njava-spring-boot\n\n\n\n\n\n\n\nNov 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCucumber with Selenium Automation\n\n\n7 min\n\n\n\ncucumber\n\n\n\n\n\n\n\nOct 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpring Boot Authentication and Authorization\n\n\n26 min\n\n\n\nspring-boot\n\n\n\n\n\n\n\nJul 10, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Partha Sai Guttikonda",
    "section": "",
    "text": "Welcome to my portfolio! ğŸš€ Iâ€™m Partha Sai Guttikonda, a dedicated and innovative Computational Biologist and Full-Stack Engineer with a deep passion for leveraging machine learning and high-performance computing to solve complex problems. ğŸ§ ğŸ’» With a Masterâ€™s degree in Computer Science and Engineering from the University of Texas at Arlington and hands-on experience managing advanced GPU clusters and developing scalable web applications, Iâ€™ve successfully led projects that merge cutting-edge technology with practical applications. ğŸŒŸ Explore my work to see how Iâ€™ve contributed to advancements in medical imaging, cloud infrastructure optimization, and more. ğŸ¥â˜ï¸ Letâ€™s collaborate and push the boundaries of whatâ€™s possible! ğŸŒâœ¨"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Partha Sai Guttikonda",
    "section": "",
    "text": "Welcome to my portfolio! ğŸš€ Iâ€™m Partha Sai Guttikonda, a dedicated and innovative Computational Biologist and Full-Stack Engineer with a deep passion for leveraging machine learning and high-performance computing to solve complex problems. ğŸ§ ğŸ’» With a Masterâ€™s degree in Computer Science and Engineering from the University of Texas at Arlington and hands-on experience managing advanced GPU clusters and developing scalable web applications, Iâ€™ve successfully led projects that merge cutting-edge technology with practical applications. ğŸŒŸ Explore my work to see how Iâ€™ve contributed to advancements in medical imaging, cloud infrastructure optimization, and more. ğŸ¥â˜ï¸ Letâ€™s collaborate and push the boundaries of whatâ€™s possible! ğŸŒâœ¨"
  },
  {
    "objectID": "index.html#areas-of-interest",
    "href": "index.html#areas-of-interest",
    "title": "Partha Sai Guttikonda",
    "section": "Areas of Interest",
    "text": "Areas of Interest\nğŸ§  Artificial Intelligence and Machine Learning\nğŸ”¬ Medical Imaging and Bioinformatics\nğŸ“Š Data Analysis and Visualization\nğŸš€ High-Performance Computing and GPU Utilization\nğŸŒ Cloud Computing and Infrastructure Optimization\nğŸ”§ Software Development and Full-Stack Engineering\nğŸ“ˆ Predictive Modeling and Algorithm Development\nğŸ”„ Automation of Data Pipelines and Workflows\nğŸŒ Environmental Impact and Sustainability\nğŸ–¥ï¸ Computer Vision and Image Processing\nğŸ“š Continuous Learning and Research in AI"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Partha Sai Guttikonda",
    "section": "Education",
    "text": "Education\nUniversity of Texas at Arlington | USA\nMSc in CSE | GPA: 3.99\nSreenidhi Institute of Technology | IND\nBTech in CSE | GPA: 3.89"
  },
  {
    "objectID": "publications/visvr.html",
    "href": "publications/visvr.html",
    "title": "SpatialVisVR:An Immersive, Multiplexed Medical Image Viewer With Contextual Similar-Patient Search",
    "section": "",
    "text": "IEEE CIBCB 2024\nIn modern pathology, multiplexed immunofluorescence (mIF) and multiplex immunohistochemistry (mIHC) bring both vast opportunities and challenges. These techniques illuminate complex tumor microenvironment interactions, necessitating intuitive visualization tools. With the rise of electronic health records (EHR) and information overload for physicians, integrating advanced technologies becomes essential. Enter SpatialVisVR: a versatile VR platform for comparing medical images, adaptable for data privacy on embedded hardware. Clinicians can capture pathology slides in real-time via mobile, then SpatialVisVR employs a deep learning algorithm to match and display similar mIF images. This interface allows for adding or removing up to 100 multiplexed protein channels, aiding immuno-oncology decisions. Ultimately, SpatialVisVR aims to refine diagnostic processes, promoting a holistic, efficient approach to immuno-oncology research and treatment. arxiv link"
  },
  {
    "objectID": "blog_posts/2022-11-27-spring-data-jpa.html",
    "href": "blog_posts/2022-11-27-spring-data-jpa.html",
    "title": "Spring Data JPA",
    "section": "",
    "text": "click here to read this in medium\n\nSpring Data JPA provides repository support for the Jakarta Persistence APIÂ (JPA).\n\n\n\n\nPhoto by Markus Spiske onÂ Unsplash\n\n\n\nSpring Data JPA provides repository support for the Jakarta Persistence API(JPA).It is used to improve the implementation of data access layers by reducing the efforts to the amount thatâ€™s actuallyÂ needed.\n\n\nâ›¹ï¸â€â™‚ï¸Dependencies\n\n\nThe below dependency needs to be in the build.gradle file.\n\n&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.data&lt;/groupId&gt;    &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt;  &lt;/dependency&gt;&lt;dependencies&gt;\n\n\n\nPhoto by Tracy Adams onÂ Unsplash\n\n\n\nğŸ™ŒğŸ»Basic concepts\n\n\nIn general, We use CrudRepository for the CREATE, READ, UPDATE and DELETE operations and PagingAndSortingRepository for pagination and sort records. In JpaRepository provides JPA related methods such as flushing the persistence context and delete records in a batch. So JpaRepository inherities both the CrudRepository and PagingAndSorting.Addtional to that it gives a different methods to filter, save and query from the repository.\n\n\nğŸ‘‰Creating Repository Interface:\n\n\nSo in this interface we can give the method names and spring will take care of logic in it.Note:- All the below example need to be inside these kind of interface which extends JpaRepository.\n\n@Repositorypublic interface ProductRepository extends JpaRepository&lt;Product, Long&gt; {    Product findByName(String productName);}\n\n\n\nPhoto by Aron Visuals onÂ Unsplash\n\n\n\nğŸ§â€â™‚ï¸Methods we can use inÂ JPA\n\n\nCURD Operations and PagingAndSorting Operations:\n\n&lt;S extends T&gt; S save(S entity); //--&gt;save entity to DBOptional&lt;T&gt; findById(ID primaryKey); //--&gt;find entity from DBIterable&lt;T&gt; findAll();//--&gt;get ALLlong count();//--&gt; get count of entitiesvoid delete(T entity);// --&gt; delete an entityboolean existsById(ID primaryKey);// --&gt; is exist by IDIterable&lt;T&gt; findAll(Sort sort);Page&lt;T&gt; findAll(Pageable pageable);//example below  repository.findAll(PageRequest.of(1, 20));long countByLastname(String lastname); // we can use any field name in place of Lastnamelong deleteByLastname(String lastname);List&lt;User&gt; removeByLastname(String lastname);\n\nQuery Methods:\n\nList&lt;Person&gt; findByLastname(String lastname);Optional&lt;T&gt; findById(ID id);User findByEmailAddress(EmailAddress emailAddress);List&lt;Person&gt; findByEmailAddressAndLastname(EmailAddress emailAddress, String lastname);// Enables the distinct flag for the queryList&lt;Person&gt; findDistinctPeopleByLastnameOrFirstname(String lastname, String firstname);List&lt;Person&gt; findPeopleDistinctByLastnameOrFirstname(String lastname, String firstname);// Enabling ignoring case for an individual propertyList&lt;Person&gt; findByLastnameIgnoreCase(String lastname);// Enabling ignoring case for all suitable propertiesList&lt;Person&gt; findByLastnameAndFirstnameAllIgnoreCase(String lastname, String firstname);// Enabling static ORDER BY for a queryList&lt;Person&gt; findByLastnameOrderByFirstnameAsc(String lastname);List&lt;Person&gt; findByLastnameOrderByFirstnameDesc(String lastname);\n\nIn the above example we can create the methods in interface as we need using the Distinct flag, Ignore Case and order BY. Also, we can use And, Or to pass multiple parameters to theÂ method.\n\n\nProperty Expressions:\n\n\nIf you have a case where you want to get a entity based on nested property for example we want to get list of People who has a given zipcode, Zipcode is present inside Address. So this case we can use the belowÂ code.\n\nList&lt;Person&gt; findByAddressZipCode(ZipCode zipCode);//better wayList&lt;Person&gt; findByAddress_ZipCode(ZipCode zipCode);//also correct\n\nSpecial Parameter handling:\n\nPage&lt;User&gt; findByLastname(String lastname, Pageable pageable);Slice&lt;User&gt; findByLastname(String lastname, Pageable pageable);List&lt;User&gt; findByLastname(String lastname, Sort sort);List&lt;User&gt; findByLastname(String lastname, Pageable pageable);//SORT exampleSort sort = Sort.by(\"firstname\").ascending()  .and(Sort.by(\"lastname\").descending());TypedSort&lt;Person&gt; person = Sort.sort(Person.class);Sort sort = person.by(Person::getFirstname).ascending()  .and(person.by(Person::getLastname).descending());\n\nLimiting QueryÂ Results:\n\nUser findFirstByOrderByLastnameAsc();User findTopByOrderByAgeDesc();Page&lt;User&gt; queryFirst10ByLastname(String lastname, Pageable pageable);Slice&lt;User&gt; findTop3ByLastname(String lastname, Pageable pageable);List&lt;User&gt; findFirst10ByLastname(String lastname, Sort sort);List&lt;User&gt; findTop10ByLastname(String lastname, Pageable pageable);\n\nStreamble:\n\n\nNow I came across a point where we need to get entities based on condition if name contains two letters in it I needÂ them.\n\ninterface PersonRepository extends Repository&lt;Person, Long&gt; {  Streamable&lt;Person&gt; findByFirstnameContaining(String firstname);  Streamable&lt;Person&gt; findByLastnameContaining(String lastname);}Streamable&lt;Person&gt; result = repository.findByFirstnameContaining(\"av\")  .and(repository.findByLastnameContaining(\"ea\"));\n\nStreaming QueryÂ Results:\n\n\nWe can run the Query asÂ below.\n\n@Query(\"select u from User u\")Stream&lt;User&gt; findAllByCustomQueryAndStream();Stream&lt;User&gt; readAllByFirstnameNotNull();@Query(\"select u from User u\")Stream&lt;User&gt; streamAllPaged(Pageable pageable);\n\n\n\nPhoto by Sai Kiran Anagani onÂ Unsplash\n\n\n\nAsynchronous QueryÂ Results:\n\n\nAsynchronous way to runÂ Queries.\n\n@AsyncFuture&lt;User&gt; findByFirstname(String firstname);@AsyncCompletableFuture&lt;User&gt; findOneByFirstname(String firstname);//useageCompletableFuture&lt;User&gt; user= findByFirstname(\"Macintosh\");user(System.out::println);\n\nReferances:\n\n\ndocs.spring.io/spring-data/jpa/docs/current/reference/html/#repositories.core-concepts\n\n\nPardhu Guttikonda - Medium\n\n\n\n\nPhoto by Wilhelm Gunkel onÂ Unsplash"
  },
  {
    "objectID": "blog_posts/2024-05-09-grad-cam-visualisation-of-resnet-50-s-decision-pathways.html",
    "href": "blog_posts/2024-05-09-grad-cam-visualisation-of-resnet-50-s-decision-pathways.html",
    "title": "Grad-CAM Visualisation of ResNet-50â€™s Decision Pathways",
    "section": "",
    "text": "click here to read this in medium\n\nTracing ResNet-50 Focus trands with Grad-CAM.\n\n\n\n\nhttps://azati.ai/image-detection-recognition-and-classification-with-machine-learning/\n\n\n\nUnderstanding How AI Sees theÂ WorldğŸŒ\n\n\nImagine an AI as an artist trying to paint a picture but first needing to decide what part of a scene is worth focusing on. In this article, we explore a tool called Grad-CAM, which helps us visualize what catches the AIâ€™s attention when it looks at an image. This tool is particularly useful for understanding complex image recognition models like ResNet-50, a type of deep neural network renowned for its accuracy in identifying objects inÂ images.\n\n\n\n\nour inputÂ Image\n\n\n\n\n\nsample output\n\n\n\nGetting StartedğŸ™ŒğŸ»\n\n\nTo start, we need an image. Think of it as the scene our AI artist is going to paint. We use a standard JPEG image for this purpose. Our AI, powered by a model called ResNet-50, processes this image not just as a whole but looks deeply at various parts to decide what itÂ sees.\n\n\nPeeking Into the AIâ€™s Mind (Grad-Cam)ğŸ’¡\n\n\nTo peek into what the AI is focusing on, we use Grad-CAM. This tool generates heatmaps that overlay on the original image. These heatmaps change color in areas where the AI is paying more attention. Thus, by looking at these heatmaps, we can understand which parts of the image are most important for the AIâ€™s decision-making.\n\n\n\n\nPhoto by Clemens van Lay onÂ Unsplash\n\n\n\nStep-by-Step Through theÂ Code:-\n\n.â”œâ”€â”€ ResNet50Vis.ipynbâ”œâ”€â”€ sample.jpegâ”œâ”€â”€ result.gif(animated gif is here result)â””â”€â”€ images    â””â”€â”€ (genarated images will be here)\n\nHere is the file structure so we have only ResNet50Vis.ipynb and sample.jpeg files will be in the working directory.\n\n\nPrepare Utils and Model Wrapping:Here we are creatingÂ reusable\n\nimport warningswarnings.filterwarnings('ignore')from torchvision import transformsfrom datasets import load_datasetfrom pytorch_grad_cam import run_dff_on_image, GradCAMfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTargetfrom pytorch_grad_cam.utils.image import show_cam_on_imagefrom PIL import Imageimport numpy as npimport cv2import torchimport imageiofrom typing import List, Callable, Optionalimage = Image.open('./sample.jpeg')img_tensor = transforms.ToTensor()(image)class HuggingfaceToTensorModelWrapper(torch.nn.Module):    def __init__(self, model):        super(HuggingfaceToTensorModelWrapper, self).__init__()        self.model = model    def forward(self, x):        return self.model(x).logitsdef category_name_to_index(model, category_name):    name_to_index = dict((v, k) for k, v in model.config.id2label.items())    return name_to_index[category_name]    def run_grad_cam_on_image(model: torch.nn.Module,                          target_layer: torch.nn.Module,                          targets_for_gradcam: List[Callable],                          reshape_transform: Optional[Callable],                          input_tensor: torch.nn.Module=img_tensor,                          input_image: Image=image,                          method: Callable=GradCAM):    with method(model=HuggingfaceToTensorModelWrapper(model),                 target_layers=[target_layer],                 reshape_transform=reshape_transform) as cam:        repeated_tensor = input_tensor[None, :].repeat(len(targets_for_gradcam), 1, 1, 1)        batch_results = cam(input_tensor=repeated_tensor,                            targets=targets_for_gradcam)        results = []        for grayscale_cam in batch_results:            visualization = show_cam_on_image(np.float32(input_image)/255,                                              grayscale_cam,                                              use_rgb=True)            visualization = cv2.resize(visualization,                                       (visualization.shape[1]//2, visualization.shape[0]//2))            results.append(visualization)        return np.hstack(results)        def print_top_categories(model, img_tensor, top_k=5):    logits = model(img_tensor.unsqueeze(0)).logits    indices = logits.cpu()[0, :].detach().numpy().argsort()[-top_k :][::-1]    for i in indices:        print(f\"Predicted class {i}: {model.config.id2label[i]}\")\n\nTarget IdentificationÂ :\n\n\nnow lets set the target label for which we will be genarating heat maps. As per our input image our target lable will cairn, cairnÂ terrier\n\nfrom transformers import ResNetForImageClassificationmodel = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")targets_for_gradcam = [ClassifierOutputTarget(category_name_to_index(model, \"cairn, cairn terrier\"))]\n\nRunning Grad-CAM:\n\n\nHere we will be running gradCam on every stage of resnet50 and store the heatmap image to list_of_images.\n\nlist_of_images = []for i in model.resnet.encoder.stages:    for j in i.layers:        target_layer = j        list_of_images.append(Image.fromarray(run_grad_cam_on_image(model=model,                      target_layer=target_layer,                      targets_for_gradcam=targets_for_gradcam,                      reshape_transform=None)))print_top_categories(model, img_tensor)\n\nVisualization and Animation:\n\n\nGreat now can creat gif with our list ofÂ images.\n\nimage_files = []for i, img in enumerate(list_of_images):    path = f'images/temp_image_{i}.png'    img.save(path)    image_files.append(path)with imageio.get_writer('my_animation.gif', mode='I', duration=0.5) as writer:    for filename in image_files:        image = imageio.imread(filename)        writer.append_data(image)from IPython.display import Image, displaydisplay(Image(filename='./my_animation.gif'))\n\nResults:\n\n\n\n\nresult gif\n\n\n\nInsights:\n\n\nBy using the gradient values of each pixel in the image, we have generated heatmaps for all 15 stages of the encoder. These 15 heatmaps have been collected in a folder named â€˜images.â€™ Subsequently, we created a GIF that illustrates how an algorithm shifts its focus within anÂ image.\n\n\nComplete code is avaliable at https://github.com/propardhu/ResNet_50_Vis\n\n\n\n\nPhoto by Kelly Sikkema onÂ Unsplash\n\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2024-05-22-building-an-advanced-image-search-system-with-machine-learning-and-elasticsearch.html",
    "href": "blog_posts/2024-05-22-building-an-advanced-image-search-system-with-machine-learning-and-elasticsearch.html",
    "title": "Building an Advanced Image Search System with Machine Learning and ElasticSearch",
    "section": "",
    "text": "click here to read this in medium\n\nIn todayâ€™s digital world, having a powerful image search system is invaluable. Imagine being able to search for images using other images rather than keywords. This article will guide you through building such an advanced image search system using machine learning techniques. Weâ€™ll leverage OpenAIâ€™s CLIP model to process images into feature vectors and Elasticsearch (part of the ELK stack) to store and search these vectors using cosine similarity.\n\n\n\n\npic byÂ meâ¤ï¸\n\n\n\nUnderstanding Image Search with MachineÂ Learning\n\n\nWhat is ImageÂ Search?\n\n\nImage search is the process of finding images that are visually similar to a query image. Traditional image search engines rely on metadata or keywords associated with images. However, with advancements in machine learning, we can now search for images based on their visualÂ content.\n\n\nHow Does itÂ Work?\n\n\n\nFeature Extraction: Transform images into feature vectors that capture their visualÂ content.\n\n\nIndexing: Store these feature vectors in a database.\n\n\nSearching: Compare feature vectors using a similarity metric (e.g., cosine similarity) to find the most similarÂ images.\n\n\n\n\n\nPhoto by Patrick Tomasso onÂ Unsplash\n\n\n\nOur Approach: Using CLIP and Elasticsearch\n\n\nWhat isÂ CLIP?\n\n\nCLIP (Contrastive Languageâ€“Image Pre-Training) is a model developed by OpenAI that can understand images and text in a unified manner. It can transform an image into a feature vector that encapsulates the imageâ€™s visualÂ content.\n\n\nWhy Elasticsearch?\n\n\nElasticsearch is a powerful search engine that supports efficient storage and querying of large datasets. With the k-NN (k-nearest neighbors) feature, Elasticsearch can quickly find similar vectors, making it ideal for our image searchÂ system.\n\n\n\n\nPhoto by Suzi Kim onÂ Unsplash\n\n\n\nStep-by-Step Implementation\n\n\nStep 1: Set Up the ELK Stack UsingÂ Docker\n\n\nFirst, we need to set up Elasticsearch and Kibana using Docker.For setting up the ElasticSearch, Logstash and Kibana. Please clone this repo (https://github.com/propardhu/Docker_ELK_Image_Search) and compose up the setup.Verify the setup:Elasticsearch: http://localhost:9200Kibana: http://localhost:5601username: elasticpassword: changeme\n\n\nStep 2: Prepare and Index Images UsingÂ Python\n\n\nNext, we will prepare and index images into Elasticsearch using the Oxford PetsÂ dataset.\n\n\n2.1. Install Dependencies\n\n!pip install torch transformers pillow requests torchvision matplotlib\n\n2.2. Download and Preprocess the Oxford PetsÂ Dataset\n\nimport torchfrom transformers import CLIPProcessor, CLIPModelfrom PIL import Imageimport requestsimport jsonimport osfrom torchvision import datasets, transformsfrom torch.utils.data import DataLoader, Subset# Load the CLIP model and processormodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")# Function to preprocess images and extract featuresdef extract_features(image):    inputs = processor(images=image, return_tensors=\"pt\")    with torch.no_grad():        image_features = model.get_image_features(**inputs)    image_features = image_features / image_features.norm(dim=-1, keepdim=True)    return image_features.squeeze().tolist()# Directory to save the datasetdataset_dir = \"./oxford_pets\"# Download and prepare the dataset (using Oxford Pets for demo)transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])dataset = datasets.OxfordIIITPet(root=dataset_dir, download=True, transform=transform)# Take a subset of 100 imagessubset_indices = list(range(100))subset = Subset(dataset, subset_indices)data_loader = DataLoader(subset, batch_size=1, shuffle=False)# Ensure there are at least 100 imagesassert len(subset) &gt;= 100, \"Dataset should contain at least 100 images.\"\n\n2.3. Index Features in Elasticsearch\n\n# Elasticsearch settingsES_HOST = \"http://localhost:9200\"ES_INDEX = \"image-index\"ES_USER = \"elastic\"ES_PASS = \"changeme\"def index_image(image, label, image_id):    features = extract_features(image)    document = {        \"name\": f\"image_{image_id}\",        \"label\": label,        \"vector\": features    }    response = requests.post(        f\"{ES_HOST}/{ES_INDEX}/_doc/{image_id}\",        headers={\"Content-Type\": \"application/json\"},        auth=(ES_USER, ES_PASS),        data=json.dumps(document)    )    return response.json()# Index the images with labelsfor i, (image, label) in enumerate(data_loader):    # Convert tensor to PIL image    image = transforms.ToPILImage()(image[0])    label = dataset.classes[label]    result = index_image(image, label, i)    image_path = os.path.join(dataset_dir, f\"image_{i}.jpg\")    image.save(image_path)  # Save the image for later retrieval    print(f\"Indexed image {i} with label '{label}': {result}\")\n\nStep 3: Perform Image-to-Image Search and DisplayÂ Images\n\n\n3.1. Search for SimilarÂ Images\n\nimport matplotlib.pyplot as plt# Function to search for similar imagesdef search_similar_images(query_image_path, k=5):    query_image = Image.open(query_image_path)    query_features = extract_features(query_image)    search_query = {        \"knn\": {            \"field\": \"vector\",            \"query_vector\": query_features,            \"k\": k,            \"num_candidates\": 100        }    }    response = requests.post(        f\"{ES_HOST}/{ES_INDEX}/_knn_search\",        headers={\"Content-Type\": \"application/json\"},        auth=(ES_USER, ES_PASS),        data=json.dumps(search_query)    )    return response.json()# Function to display imagesdef display_images(query_image_path, search_results):    query_image = Image.open(query_image_path)    fig, axes = plt.subplots(1, 6, figsize=(20, 5))    # Display the query image    axes[0].imshow(query_image)    axes[0].set_title(\"Query Image\")    axes[0].axis('off')    # Display the top 5 similar images    for i, hit in enumerate(search_results['hits']['hits']):        image_id = hit['_id']        label = hit['_source']['label']        similar_image_path = os.path.join(dataset_dir, f\"image_{image_id}.jpg\")                similar_image = Image.open(similar_image_path)        axes[i + 1].imshow(similar_image)        axes[i + 1].set_title(f\"Label: {label}\\nScore: {hit['_score']:.2f}\")        axes[i + 1].axis('off')    plt.show()# Example search with a query image from the datasetfrom random import randintquery_image, _ = subset[randint(1, 100)]query_image = transforms.ToPILImage()(query_image)  # Convert tensor to PIL imagequery_image_path = \"./query_image.jpg\"  # Save the query image to this pathquery_image.save(query_image_path)  # Save the PIL image to the specified pathquery_result = search_similar_images(query_image_path)# Display the resultsdisplay_images(query_image_path, query_result)\n\n\n\nSample result-1\n\n\n\n\n\nSample result-2\n\n\n\nNote: I have created An flask app to show the searchÂ results.\n\n\nAll the code is available at\n\n\nGitHub - propardhu/Docker_ELK_Image_Search\n\n\nConclusion\n\n\nIn this article, we built an advanced image search system using OpenAIâ€™s CLIP model and Elasticsearch. By setting up the ELK stack with Docker, downloading and preparing the Oxford Pets dataset, indexing image features into Elasticsearch, and performing image.\n\n\nThank you..!\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2024-02-18-simplifying-kafka-effortless-stream-processing-with-docker.html",
    "href": "blog_posts/2024-02-18-simplifying-kafka-effortless-stream-processing-with-docker.html",
    "title": "Simplifying Kafka: Effortless Stream Processing with Docker",
    "section": "",
    "text": "click here to read this in medium\n\nUnlock the power of real-time data processing with Apache Kafka, and streamline your setup with Docker for an efficient, scalable solution.\n\n\n\n\nPhoto by Hunter Harritt onÂ Unsplash\n\n\n\nIntroduction to ApacheÂ Kafka\n\n\nImagine a river, endlessly flowing with data from countless sources. This is the world of streaming data, and navigating it requires a robust and efficient system. Enter Apache Kafka: a powerhouse designed to manage and process vast streams of real-time data. Kafka acts as an organizing force, ensuring every bit of data is processed systematically, maintaining order in the relentless stream of information.\n\n\nExploring Kafka, Zookeeper, and Fault Tolerance\n\n\nTo truly harness the capabilities of Kafka, along with its components like Zookeeper and its fault tolerance mechanisms, itâ€™s essential to delve into the core concepts and functionalities that make Kafka a critical tool in data streaming and processing. More info on this topicÂ this.\n\n\nThe Role of Kafka asÂ Storage\n\n\nThe question arises: beyond its primary role, can Kafka be utilized as a storage system? This exploration reveals Kafkaâ€™s capabilities beyond real-time data processing. More info on this topicÂ here.\n\n\nKey Terminology inÂ Kafka\n\n\nFamiliarizing yourself with Kafkaâ€™s terminology is crucial for navigating its ecosystem:\n\n\n\nTopic: A specific channel where data flows, categorized under a feedÂ name.\n\n\nPartition: A segment within a topic for scalability, allowing parallel data consumption.\n\n\nReplica: Partition clones for fault tolerance, ensuring data availability.\n\n\nProducer: Applications that send data to Kafka, deciding on the partition for eachÂ record.\n\n\nConsumer: Applications that read and process the data stream fromÂ topics.\n\n\nConsumer Group: A collection of consumers sharing an identifier to divide processing workload.\n\n\nBroker: The heart of the Kafka cluster, managing data storage and communication.\n\n\nZookeeper: Coordinates Kafkaâ€™s brokers, managing configuration and synchronization.\n\n\nOffset: A unique identifier for each record within a partition.\n\n\nLeader and Followers: Designations within replicas for handling requests and ensuring data integrity.\n\n\n\nDeploying Kafka withÂ Docker\n\n\nWe leverage Confluentâ€™s open-source Kafka images for a Docker-based approach, simplifying Kafka deployment and making stream processing power readily accessible.\n\n\n\n\nPhoto by Brett Jordan onÂ Unsplash\n\n\n\nPractical Kafka Deployment: Docker andÂ Python\n\n\nTo provide a hands-on example, weâ€™ve prepared a comprehensive setup including a Docker Compose file and Python scripts for message handling.\n\n\nExplore Our GitHub Repository\n\n\nAccess the necessary files on our GitHub repository:\n\nğŸ“¦POC_Kafka_python â”£ ğŸ“‚connectors â”£ ğŸ“œ.gitattributes â”£ ğŸ“œLICENSE â”£ ğŸ“œREADME.md â”£ ğŸ“œconduktor.yml â”£ ğŸ“œconsumer.py â”£ ğŸ“œdocker-compose.yml â”— ğŸ“œproducer.py\n\n\ndocker-compose.yml: Sets up the Confluent Kafka environment in Docker containers.\n\n\n\nPython Scripts:\n\n\n\nProducer Script: Sends 100 messages per second to a Kafka topic, showcasing Kafkaâ€™s high-volume handling.\n\n\nConsumer Script: Receives and processes messages from the Kafka topic in real-time.\n\n\n\nGetting Started\n\n\n1.Clone the Repository: Access all files for a Docker-based Kafka deployment.\n\ngit clone https://github.com/propardhu/POC_Kafka_python.git\n\n2. Launch Kafka with Docker Compose: Start the Kafka environment using.Docker Compose.\n\ncd POC_Kafka_python\n\nNow setup your username and password for the admin portal at conduktor.yml\n\nCDK_ORGANIZATION_NAME: \"python_demo_medium\"CDK_ADMIN_EMAIL: \"admin@admin.io\"CDK_ADMIN_PASSWORD: \"admin\"# in conduktor.yml\n\nNow get the docker up andÂ running\n\ndocker compose -f docker-compose.yml up\n\ndashboard will be running at http://localhost:8080/\n\n\n\n\ndocker ranÂ success\n\n\n\n\n\ndashboard\n\n\n\n3.Execute the Python Scripts: Begin sending and receiving messages with Kafka by running the PythonÂ scripts.\n\n\nrun the two python file in two different terminals to see live streaming.\n\npython producer.pypython consumer.py\nhttps://medium.com/media/08b30bbfe5eb7c9dfe4557793f4f0931/href\n\nThis practical setup showcases Kafkaâ€™s capabilities within a Docker environment, emphasizing real-world applications of streaming data management.\n\n\nWhatâ€™s Next?\n\n\nAs we continue to explore the vast potential of Kafka, our journey into the world of stream processing and data handling is far from over. Stay tuned for our upcoming articles, where we will take a deeper dive into advanced integrations and applications ofÂ Kafka:\n\n\n\nIntegrating Kafka with Spring Boot and Camel: Our next guides will delve into creating sophisticated messaging applications by leveraging Kafka with Spring Boot and Apache Camel. This integration will provide a powerful foundation for building robust, scalable applications that can process and route data efficiently.\n\n\nHarnessing Unsupervised Learning in Kafka Networks: Beyond traditional applications, weâ€™re venturing into the cutting-edge territory of machine learning. We will explore how unsupervised learning algorithms can be integrated into the Kafka network. This initiative aims to uncover insights from the diverse kinds of data streaming through Kafka. By applying machine learning, we can automate the identification of patterns, anomalies, and trends within the data, enhancing the intelligence and adaptability of ourÂ systems.\n\n\n\nThese upcoming articles will not only expand your toolkit but also open new horizons for innovation within your Kafka deployments. Whether itâ€™s through advanced application integrations or the pioneering application of machine learning, the goal is to unlock new levels of efficiency, insight, and functionality in your data streaming projects.\n\n\n\n\nPhoto by Priscilla Du Preez ğŸ‡¨ğŸ‡¦ onÂ Unsplash\n\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2023-10-13-network-checklist-for-unity-vr-apps.html",
    "href": "blog_posts/2023-10-13-network-checklist-for-unity-vr-apps.html",
    "title": "Network Checklist for Unity VR Apps",
    "section": "",
    "text": "click here to read this in medium\n\nChecklist for Internet Connection in Unity VR AppÂ Builds\n\n\n\n\nPhoto by XR Expo onÂ Unsplash\n\n\n\nWhile working on a Unity VR app for the Meta Quest, I encountered a peculiar issue. The app functioned seamlessly in debug mode on my development machine. However, when I built and installed it on the Meta Quest, the log highlighted an internet-related problem, stating, â€œcannot resolve the host name.â€ Iâ€™ve observed numerous threads on Unity communities discussing this very issue. In this article, Iâ€™ll share a checklist that has helped me address network connectivity challenges.\n\n\nCheck List:\n\n\n\nEnsure the VR device has an active Internet connection.\n\n\nReview the AndroidManifest.xml for the necessary network permissions.\n\n\nExplore the Meta supportÂ options.\n\n\n\n\n\nPhoto by Sara Kurig onÂ Unsplash\n\n\n\nSetps:\n\n\n\nEnable the manual Main Manifest in the settings:Navigate to: File &gt; Build Settings &gt; PlayerÂ Settings\n\n\n\n\n\nmy source\n\n\n\n\nIn the Player Settings, follow these steps:Go to: Player &gt; Other Settings &gt; ConfigurationChange the Internet Access to â€œRequired.â€If necessary, enable the â€œAllow Httpâ€Â options.\n\n\n\n\n\n\nMost of the time, the app should function correctly after these adjustments. If not, enable the manual Main Manifest and inspect the file for network permissions. This option can be found at: Player &gt; Publishing Settings &gt;Â Build\n\n\n\n\n\nLook for these lines inside the &lt;manifest&gt; tag but outside the &lt;application&gt; tag:\n\n&lt;uses-permission android:name=\"android.permission.INTERNET\" /&gt;&lt;uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" /&gt;\n\nHereâ€™s an example of what your AndroidManifest.xml might lookÂ like:\n\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;manifest xmlns:android=\"http://schemas.android.com/apk/res/android\"    package=\"com.unity3d.player\"    xmlns:tools=\"http://schemas.android.com/tools\"    android:versionCode=\"1\"    android:versionName=\"1.0\"&gt;    &lt;uses-permission android:name=\"android.permission.INTERNET\" /&gt;    &lt;uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" /&gt;    &lt;application&gt;        &lt;activity android:name=\"com.unity3d.player.UnityPlayerActivity\"            android:theme=\"@style/UnityThemeSelector\"&gt;            &lt;intent-filter&gt;                &lt;action android:name=\"android.intent.action.MAIN\" /&gt;                &lt;category android:name=\"android.intent.category.LAUNCHER\" /&gt;            &lt;/intent-filter&gt;            &lt;meta-data android:name=\"unityplayer.UnityActivity\" android:value=\"true\" /&gt;        &lt;/activity&gt;    &lt;/application&gt;&lt;/manifest&gt;\n\nIf the app still doesnâ€™t connect, double-check the settings mentioned above.\n\n\n\n\n\n\n\n\nThank you for reading! I hope this guide provesÂ helpful.\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2023-11-19-free-easy-portfolio-launch-customize-and-host-with-github-and-netlify.html",
    "href": "blog_posts/2023-11-19-free-easy-portfolio-launch-customize-and-host-with-github-and-netlify.html",
    "title": "Free & Easy Portfolio Launch: Customize and Host with GitHub and Netlify",
    "section": "",
    "text": "click here to read this in medium\n\n\n\n\nIntroductionÂ :\n\n\nDiscover the simplest way to put your talents on displayâ€Šâ€”â€Šfor free! This guide is your key to creating an attractive portfolio by customizing a GitHub repository and hosting it on Netlify, without spending a penny. Ideal for anyone looking to establish a professional online presence without the complexities of coding or software installation.\n\n\nSection 1:Preparing Your Environment\n\n\nRequirements: All you need is a GitHub account and a zest for creativity! This process requires no financial investment or advanced technical skills.Overview of Tools Used: Weâ€™ll be using GitHub for your codebase and Netlify for web hostingâ€Šâ€”â€Šboth available at noÂ cost.\n\n\n\n\nPhoto by Ian Schneider onÂ Unsplash\n\n\n\nSection 2: Forking the GitHub Repository\n\n\nStep-by-Step Guide to Forking: Select the GitHub repository you want and simply click the â€˜Forkâ€™ button, creating a free copy for yourÂ use.\n\n\nOpen the given github repo â†’ https://github.com/propardhu/resume-maker\n\n\n\n\nclick on Fork and create a newÂ fork\n\n\n\nSection 3: Customizing Your Portfolio\n\n\nNavigating to the JSON File: In your new repository, locate the JSON file. This is where youâ€™ll make your portfolio come toÂ life.\n\n\nğŸ‘‡Go to the resumeData.json in pulic folder â†’ public/resumeData.json\n\n\n\n\nhttps://github.com/propardhu/resume-maker/tree/main/public\n\n\n\nEditing the JSON File Online: GitHub allows you to edit this file directly on their platform. Click to edit, and start personalizing with your details. Itâ€™s free and straightforward.\n\n\nStart by modifying the default content to reflect your own profile. For a more efficient and user-friendly editing experience, consider copying the content into an online JSON editor. This approach allows for quicker and more precise adjustments tailored to yourÂ needs.\n\n\nparticles-bg\n\n\nğŸ‘† The links provided above offer a selection of diverse background options for your name, allowing you to choose the one that best suits yourÂ style.\n\n\nCommitting Changes: Save your updates with a commit, directly on GitHubâ€Šâ€”â€Šno local setup involved.\n\n\nImportant Caution: Please ensure that the JSON file remains valid after your edits. Additionally, any links that point to specific files should be located within the â€˜publicâ€™ folder of the project. This ensures proper functioning and accessibility of your portfolioâ€™s resources. Remember, a valid JSON structure and correctly placed links are crucial for the seamless performance of your portfolio.\n\n\nSection 4: Hosting onÂ Netlify\n\n\nCreating a Netlify Account: Sign up with Netlify for free using your GitHub account.Connecting GitHub to Netlify: Easily link your GitHub repository to Netlify. Their free plan is perfect for getting your portfolio online.\n\n\nA Step-by-Step Guide: Deploying on Netlify\n\n\nğŸ‘† Here we have a detailed explanation for theÂ setup.\n\n\nSection 5: Launching Your Portfolio\n\n\nDeploying the Project: With just a couple of clicks, deploy your portfolio on Netlify, completely free of charge.Custom Domain Configuration (Optional): Netlify offers free options to add a custom domain, making your portfolio standÂ out.\n\n\nConclusion\n\n\nYouâ€™ve done itâ€Šâ€”â€Šyour portfolio is now live, and it didnâ€™t cost you anything! Remember, this is just the start. Your portfolio can evolve as your skills and experiences grow.\n\n\n\n\nPhoto by Joshua Harris onÂ Unsplash\n\n\n\nThank youâ€¦.!preview few outputsÂ ğŸ™‚\n\n\n\nPardhu\n\n\nAkhilesh\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2023-07-06-image-processing-using-cnn.html",
    "href": "blog_posts/2023-07-06-image-processing-using-cnn.html",
    "title": "Image Processing using CNN",
    "section": "",
    "text": "click here to read this in medium\n\nConvolutional NeuralÂ Network\n\n\n\n\nmedium\n\n\n\nBasics â†’\n\n\n\n\nPhoto by Sebastian Bill onÂ Unsplash\n\n\n\nWhat is anÂ Image?\n\n\nAn image is nothing but an array of elements called pixels. A pixel is the smallest unit of a digital image or graphic that can be displayed and represented on a digital display device, which ranges between 0 and 255.So, image is nothing but an n * 2d Array with values ranging from 0 to 255.NoteÂ :- n depends on type of image, if the image is represented in RGB the n will be inÂ 3.\n\n\n\n\nPhoto by Jon Tyson onÂ Unsplash\n\n\n\nWe are using MNIST dataset each image is a 28X28 pixel square. Which means we will be having 1 * 28 * 28 resolution images in our dataset. Letâ€™s get the dataset and display theÂ imageğŸ˜ƒ.\n\nimport tensorflow as tfimport numpy as npfrom matplotlib import pyplot as pltfrom tensorflow.keras import utils as np_utils(X_train,y_train),(X_test,y_test) = tf.keras.datasets.mnist.load_data()X_test = X_test.reshape(X_test.shape[0], 1,28,28).astype('float32')X_test = X_test/255y_test = np_utils.to_categorical(y_test)y_test = y_test/255first_image = np.array(X_test[0], dtype='float')pixels = first_image.reshape((28, 28))plt.imshow(pixels, cmap='gray')plt.show()\n\n\n\n\nIntroductionÂ :-\n\n\nCNN contains three type of layers whichÂ are\n\n\nConvolutional Layerâ€Šâ€”â€ŠHere we will be extracting the features present in the image. Example we can find all the horizontal lines present in the image using dot product of our horizontal matrix with the image matrix, then the resultant matrix will only contain the horizontal lines.\n\n\n\n\nhorizontal lines from the image source codingÂ lane\n\n\n\n\n\nIllustration of Convolution Operation(source)\n\n\n\nPooling Layerâ€Šâ€”â€ŠIt is used to reduce the image size. By simply doing dot product for the image with a fixedÂ slider.\n\n\n\n\nfrom codingÂ lane\n\n\n\n\n\nfrom codingÂ lane\n\n\n\n\n\nfrom codingÂ lane\n\n\n\nFully-Connected layerâ€Šâ€”â€ŠHere it flattens the pixels and learns to associate features by forming all the combinations of flattenÂ objects.\n\n\n\n\nPhoto by Norbert Braun onÂ Unsplash\n\n\n\nLetâ€™s jump on theÂ task\n\n\nwe have a dataset which contains digits from 0 to 9 in the form of images. Our task is to build a CNN model to predict the digit. So out CNN layers will be in thisÂ form.\n\n\nOutput Layer(10 outputs)Hidden Layer(128 neurons)Flatten LayerDropout Layer20%Max Pooling Layer2Ã—2Convolutional Layer32 maps, 5Ã—5Visible Layer1x28x28\n\n\n\nThe first hidden layer is a Convolutional layer called Convolution2D. It consists of 32 feature maps with a size of 5Ã—5 and uses the rectifier activation function.\n\n\nThe next layer is a pooling layer called MaxPooling2D. It performs 2Ã—2 pooling, which means it takes the maximum value from a 2Ã—2 grid ofÂ values.\n\n\nA dropout layer follows, which helps with regularization. It randomly excludes 20% of the neurons in the layer during training to prevent overfitting.\n\n\nThe fifth layer is a flattened layer called Flatten. It converts the 2D matrix data from the previous layer into a 1D vector, allowing it to be processed by a fully connected layer.\n\n\nNext, there is a fully connected layer with 128 neurons and the rectifier activation function.\n\n\nFinally, the output layer consists of 10 neurons, representing the 10 classes in the classification task. It uses the softmax activation function to produce probability-like predictions for eachÂ class.\n\n\n\nCoding it:\n\nimport numpy as npfrom matplotlib import pyplot as pltfrom tensorflow.keras.utils import to_categoricalfrom keras.models import Sequentialfrom keras.layers import Densefrom tensorflow.keras import utils as np_utilsfrom keras.layers import Dropoutfrom keras.layers import Flattenfrom tensorflow.keras.layers import Conv2Dfrom tensorflow.keras.layers import MaxPooling2Dimport tensorflow as tfimport time#importing and preprocessing(X_train,y_train), (X_test, y_test)= tf.keras.datasets.mnist.load_data()X_train=X_train.reshape(X_train.shape[0], 1,28,28).astype('float32')X_test=X_test.reshape(X_test.shape[0], 1,28,28).astype('float32')X_train=X_train/255X_test=X_test/255y_train = np_utils.to_categorical(y_train)y_test= np_utils.to_categorical(y_test)num_classes=y_train.shape[1]print(num_classes)#prepare your modeldef cnn_model():    model=Sequential()    # Convolutional Layer 32 map 5X5 and input 1 * 28 * 28    model.add(Conv2D(32,5,5, padding='same',input_shape=(1,28,28), activation='relu'))    # Max Pooling Layer 2 X 2    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))    # Dropout Layer 20%    model.add(Dropout(0.2))    # Flatten Layer    model.add(Flatten())    # Hidden Layer 128 neurons    model.add(Dense(128, activation='relu'))    # Output Layer    model.add(Dense(num_classes, activation='softmax'))    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])    return modelt1 = time.time_ns()model=cnn_model()model.fit(X_train, y_train, validation_data=(X_test,y_test),epochs=10, batch_size=200, verbose=2)t2 = time.time_ns()score= model.evaluate(X_test, y_test, verbose=0)t3 = time.time_ns()train_time = t2-t1evaluavation_time = t3-t2print('The accuracy is: %.2f%%'%(score[1]))print(f'training time {train_time}, evaluvation time {evaluavation_time}')first_image = np.array(X_test[0], dtype='float')pixels = first_image.reshape((28, 28))plt.imshow(pixels, cmap='gray')plt.show()t4 = time.time_ns()test_input = first_image.reshape((-1, 1, 28, 28))k = model.predict(test_input).tolist()t5 = time.time_ns()print(f'predicted output : {k[0].index(max(k[0]))}')print(f'actual output : {y_test[0]}')print(f'prediction time {t5-t4}')\n\n\n\nPhoto by Ricardo Arce onÂ Unsplash\n\n\n\nResults\n\n\nAccuracyâ€Šâ€”â€Š97%Training run timeâ€Šâ€”â€Š7.2892 SecEvaluation run timeâ€Šâ€”â€Š0.186776 SecPrediction run time (for digit 7)â€Šâ€”â€Š0.033601Â Sec\n\n\nComplete code is available in my GitHub (https://github.com/propardhu/Pandas_Play/blob/main/CNN_mnist.ipynb)\n\nhttps://medium.com/media/9602ed028d76e3f631dae05408c7e2cd/href\n\n\nPardhu Guttikonda - Medium\n\n\nPandas_Play/CNN_mnist.ipynb at main Â· propardhu/Pandas_Play\n\n\n\n\n\nPhoto by Priscilla Du Preez onÂ Unsplash"
  },
  {
    "objectID": "blog_posts/2022-07-10-spring-boot-authentication-and-authorization.html",
    "href": "blog_posts/2022-07-10-spring-boot-authentication-and-authorization.html",
    "title": "Spring Boot Authentication and Authorization",
    "section": "",
    "text": "click here to read this in medium\n\nSpring security, JWT, Authorisations\n\n\n\n\nPhoto by Florian Berger onÂ Unsplash\n\n\n\nğŸ¥· What weÂ do\n\n\nIn this article, We will be creating a Spring boot application to demonstrate Authentication and Authorization to users. For this Demo, we will be using MongoDB database. Also For this Authentication we will be using JWT Standard, and we will be using HS512 algorithm to encode the information.\n\n\nğŸ¯Dependencies usedÂ :\n\n\nplease view at linkÂ . (https://github.com/propardhu/AuthDemoSpringBoot/blob/main/build.gradle)\n\n\nğŸ§â€â™‚ï¸Steps To beÂ followed\n\n\n\nCreate domain and repository for Both users and Authorities.\n\n\nPrepare JWT and Security Utilities.\n\n\nConfigure spring security and JWTÂ Filters.\n\n\nmongock ChangeLog to add initial users to DataBase.\n\n\n\n\n\nPhoto by Zeynep SÃ¼mer onÂ Unsplash\n\n\n\nDocument Structures of Both User and Authorities\n\n\nAuthority.java\n\n/** * An authority (a security role) used by Spring Security. */@Document(collection = \"authority\")public class Authority implements Serializable {    private static final long serialVersionUID = 1L;    @NotNull    @Size(max = 50)    @Id    private String name;    public String getName() {        return name;    }    public void setName(String name) {        this.name = name;    }    @Override    public boolean equals(Object o) {        if (this == o) {            return true;        }        if (!(o instanceof Authority)) {            return false;        }        return Objects.equals(name, ((Authority) o).name);    }    @Override    public int hashCode() {        return Objects.hashCode(name);    }    // prettier-ignore    @Override    public String toString() {        return \"Authority{\" +            \"name='\" + name + '\\'' +            \"}\";    }}\n\nUser.java\n\n/** * A user. */@org.springframework.data.mongodb.core.mapping.Document(collection = \"user\")public class User extends AbstractAuditingEntity implements Serializable {    private static final long serialVersionUID = 1L;    @Id    private String id;    @NotNull    @Pattern(regexp = Constants.LOGIN_REGEX)    @Size(min = 1, max = 50)    @Indexed    private String login;    @JsonIgnore    @NotNull    @Size(min = 60, max = 60)    private String password;    @Size(max = 50)    @Field(\"first_name\")    private String firstName;    @Size(max = 50)    @Field(\"last_name\")    private String lastName;    @Email    @Size(min = 5, max = 254)    @Indexed    private String email;    private boolean activated = false;    @Size(min = 2, max = 10)    @Field(\"lang_key\")    private String langKey;    @Size(max = 256)    @Field(\"image_url\")    private String imageUrl;    @Size(max = 20)    @Field(\"activation_key\")    @JsonIgnore    private String activationKey;    @Size(max = 20)    @Field(\"reset_key\")    @JsonIgnore    private String resetKey;    @Field(\"reset_date\")    private Instant resetDate = null;    @JsonIgnore    private Set&lt;Authority&gt; authorities = new HashSet&lt;&gt;();}\n\nUserRepository.java\n\n@Repositorypublic interface UserRepository extends MongoRepository&lt;User, String&gt; {    Optional&lt;User&gt; findOneByActivationKey(String activationKey);    List&lt;User&gt; findAllByActivatedIsFalseAndActivationKeyIsNotNullAndCreatedDateBefore(Instant dateTime);    Optional&lt;User&gt; findOneByResetKey(String resetKey);    Optional&lt;User&gt; findOneByEmailIgnoreCase(String email);    Optional&lt;User&gt; findOneByLogin(String login);    Page&lt;User&gt; findAllByIdNotNullAndActivatedIsTrue(Pageable pageable);}\n\nAuthorityRepository.java\n\n/** * Spring Data MongoDB repository for the {@link Authority} entity. */public interface AuthorityRepository extends MongoRepository&lt;Authority, String&gt; {}\n\nAuthoritiesConstants.java\n\npublic final class AuthoritiesConstants {    public static final String ADMIN = \"ROLE_ADMIN\";    public static final String USER = \"ROLE_USER\";    public static final String ANONYMOUS = \"ROLE_ANONYMOUS\";    private AuthoritiesConstants() {}}\n\nJWT Things\n\n\nğŸ‘‰ JWT workingÂ Flow:-\n\n\n\nJSON Web Token(JWT) is an open standard used to share security information between two parties like client and server. It follows one particular cryptographic algorithm to encrypt and decrypt the JSON Objects. Algorithms like Hash 512,Hash 256, RS256Â etc.\n\n\nWhen a user registers in an application, user details are sent to the server. While saving the user details. We will ensure to encrypt the password while saving into the database.(BCryptPasswordEncoder)\n\n\nWhen a user logs in to the application, details like username and password will be sent to the server. There we will be verifying the password with encrypted password. If matches, we will be creating an JWT token and sent it as a response.\n\n\nAfter getting the JWT token, we need to append the token in the header of HTTP request (For all secured endpoints, we need to follow theÂ same).\n\n\nThe JWT token contains three parts (HEADER, PAYLOAD)are Base64-URL encoded JSON and Cryptographic Signature.Note:- We need a secret key to encrypt and decryptÂ data.\n\n\nFor Authorization, we will be adding the roles of the user to the tokenÂ itself.\n\n\n\n\n\nPhoto by Georg Bommeli onÂ Unsplash\n\n\n\nTokenProvider.javaHere we will be writing the methods to createTokens, getAuthentications from token and validate token.Replace â€œKEYâ€ with secretKey.\n\n@Componentpublic class TokenProvider {    private final Logger log = LoggerFactory.getLogger(TokenProvider.class);    private static final String AUTHORITIES_KEY = \"auth\";    private final Key key;    private final JwtParser jwtParser;    private final long tokenValidityInMilliseconds;    private final long tokenValidityInMillisecondsForRememberMe;    public TokenProvider() {        byte[] keyBytes;        String secret = \"KEY\";        if (!ObjectUtils.isEmpty(secret)) {            log.debug(\"Using a Base64-encoded JWT secret key\");            keyBytes = Decoders.BASE64.decode(secret);        } else {            log.warn(                \"Warning: the JWT key used is not Base64-encoded. \" +                \"We recommend using the `jhipster.security.authentication.jwt.base64-secret` key for optimum security.\"            );            secret = \"YWQzMmJiZjgwMDliY2M4NWE0ZjVkOWUxZmRjYTcwMDc2OTZkN2Y5MzQ3ODQ4N2M2YmExNTVmNDFjMDdhZGUzZDRmZDE2OGFkMTc1NmE4MWVmYTIxZDI3YWIzZTNhNzQ1YjNhMzE1ZGVmMWRhNWQxZGFhN2I3NjQzMWRkNjczODY=\";            keyBytes = secret.getBytes(StandardCharsets.UTF_8);        }        key = Keys.hmacShaKeyFor(keyBytes);        jwtParser = Jwts.parserBuilder().setSigningKey(key).build();        this.tokenValidityInMilliseconds = 1000 * 700;        this.tokenValidityInMillisecondsForRememberMe = 1000 * 700;    }    public String createToken(Authentication authentication, boolean rememberMe) {        String authorities = authentication.getAuthorities().stream().map(GrantedAuthority::getAuthority).collect(Collectors.joining(\",\"));        long now = (new Date()).getTime();        Date validity;        if (rememberMe) {            validity = new Date(now + this.tokenValidityInMillisecondsForRememberMe);        } else {            validity = new Date(now + this.tokenValidityInMilliseconds);        }        return Jwts            .builder()            .setSubject(authentication.getName())            .claim(AUTHORITIES_KEY, authorities)            .signWith(key, SignatureAlgorithm.HS512)            .setExpiration(validity)            .compact();    }    public Authentication getAuthentication(String token) {        Claims claims = jwtParser.parseClaimsJws(token).getBody();        Collection&lt;? extends GrantedAuthority&gt; authorities = Arrays            .stream(claims.get(AUTHORITIES_KEY).toString().split(\",\"))            .filter(auth -&gt; !auth.trim().isEmpty())            .map(SimpleGrantedAuthority::new)            .collect(Collectors.toList());        User principal = new User(claims.getSubject(), \"\", authorities);        return new UsernamePasswordAuthenticationToken(principal, token, authorities);    }    public boolean validateToken(String authToken) {        try {            jwtParser.parseClaimsJws(authToken);            return true;        } catch (JwtException | IllegalArgumentException e) {            log.info(\"Invalid JWT token.\");            log.trace(\"Invalid JWT token trace.\", e);        }        return false;    }}\n\nJWTConfigurer.javaNow We need to add JWTFilter with tokenProvider to the HttpSecurity, That can be overwritten by extending SecurityConfigurerAdapter&lt;DefaultSecurityFilterChain, HttpSecurity&gt;.\n\npublic class JWTConfigurer extends SecurityConfigurerAdapter&lt;DefaultSecurityFilterChain, HttpSecurity&gt; {    private final TokenProvider tokenProvider;    public JWTConfigurer(TokenProvider tokenProvider) {        this.tokenProvider = tokenProvider;    }    @Override    public void configure(HttpSecurity http) {        JWTFilter customFilter = new JWTFilter(tokenProvider);        http.addFilterBefore(customFilter, UsernamePasswordAuthenticationFilter.class);    }}\n\nJWTFilter.javaThis class will be extending the GenericFilterBean class and we can add Filter by overriding doFilter method. So here we will be validating all the request with bearer token. if the request do not have it can access only publicÂ APIâ€™s.\n\npublic class JWTFilter extends GenericFilterBean {    public static final String AUTHORIZATION_HEADER = \"Authorization\";    private final TokenProvider tokenProvider;    public JWTFilter(TokenProvider tokenProvider) {        this.tokenProvider = tokenProvider;    }    @Override    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)        throws IOException, ServletException {        HttpServletRequest httpServletRequest = (HttpServletRequest) servletRequest;        String jwt = resolveToken(httpServletRequest);        if (StringUtils.hasText(jwt) && this.tokenProvider.validateToken(jwt)) {            Authentication authentication = this.tokenProvider.getAuthentication(jwt);            SecurityContextHolder.getContext().setAuthentication(authentication);        }        filterChain.doFilter(servletRequest, servletResponse);    }    private String resolveToken(HttpServletRequest request) {        String bearerToken = request.getHeader(AUTHORIZATION_HEADER);        if (StringUtils.hasText(bearerToken) && bearerToken.startsWith(\"Bearer \")) {            return bearerToken.substring(7);        }        return null;    }}\n\nService which provides user details from DataBase need to be declared as component to avoid dependency cycle in ourÂ project.\n\n/** * Authenticate a user from the database. */@Component(\"userDetailsService\")public class DomainUserDetailsService implements UserDetailsService {    private final Logger log = LoggerFactory.getLogger(DomainUserDetailsService.class);    private final UserRepository userRepository;    public DomainUserDetailsService(UserRepository userRepository) {        this.userRepository = userRepository;    }    @Override    public UserDetails loadUserByUsername(final String login) {        log.debug(\"Authenticating {}\", login);        if (new EmailValidator().isValid(login, null)) {            return userRepository                .findOneByEmailIgnoreCase(login)                .map(user -&gt; createSpringSecurityUser(login, user))                .orElseThrow(() -&gt; new UsernameNotFoundException(\"User with email \" + login + \" was not found in the database\"));        }        String lowercaseLogin = login.toLowerCase(Locale.ENGLISH);        return userRepository            .findOneByLogin(lowercaseLogin)            .map(user -&gt; createSpringSecurityUser(lowercaseLogin, user))            .orElseThrow(() -&gt; new UsernameNotFoundException(\"User \" + lowercaseLogin + \" was not found in the database\"));    }    private org.springframework.security.core.userdetails.User createSpringSecurityUser(String lowercaseLogin, User user) {        if (!user.isActivated()) {            throw new UserNotActivatedException(\"User \" + lowercaseLogin + \" was not activated\");        }        List&lt;GrantedAuthority&gt; grantedAuthorities = user            .getAuthorities()            .stream()            .map(authority -&gt; new SimpleGrantedAuthority(authority.getName()))            .collect(Collectors.toList());        return new org.springframework.security.core.userdetails.User(user.getLogin(), user.getPassword(), grantedAuthorities);    }}\n\nSecurityUtils.javaHere we will be writing methods related to current user login like getCurrentUserName etc.\n\n/** * Utility class for Spring Security. */public final class SecurityUtils {    private SecurityUtils() {}    /**     * Get the login of the current user.     *     * @return the login of the current user.     */    public static Optional&lt;String&gt; getCurrentUserLogin() {        SecurityContext securityContext = SecurityContextHolder.getContext();        return Optional.ofNullable(extractPrincipal(securityContext.getAuthentication()));    }    private static String extractPrincipal(Authentication authentication) {        if (authentication == null) {            return null;        } else if (authentication.getPrincipal() instanceof UserDetails) {            UserDetails springSecurityUser = (UserDetails) authentication.getPrincipal();            return springSecurityUser.getUsername();        } else if (authentication.getPrincipal() instanceof String) {            return (String) authentication.getPrincipal();        }        return null;    }    /**     * Get the JWT of the current user.     *     * @return the JWT of the current user.     */    public static Optional&lt;String&gt; getCurrentUserJWT() {        SecurityContext securityContext = SecurityContextHolder.getContext();        return Optional            .ofNullable(securityContext.getAuthentication())            .filter(authentication -&gt; authentication.getCredentials() instanceof String)            .map(authentication -&gt; (String) authentication.getCredentials());    }    /**     * Check if a user is authenticated.     *     * @return true if the user is authenticated, false otherwise.     */    public static boolean isAuthenticated() {        Authentication authentication = SecurityContextHolder.getContext().getAuthentication();        return authentication != null && getAuthorities(authentication).noneMatch(AuthoritiesConstants.ANONYMOUS::equals);    }    /**     * Checks if the current user has any of the authorities.     *     * @param authorities the authorities to check.     * @return true if the current user has any of the authorities, false otherwise.     */    public static boolean hasCurrentUserAnyOfAuthorities(String... authorities) {        Authentication authentication = SecurityContextHolder.getContext().getAuthentication();        return (            authentication != null && getAuthorities(authentication).anyMatch(authority -&gt; Arrays.asList(authorities).contains(authority))        );    }    /**     * Checks if the current user has none of the authorities.     *     * @param authorities the authorities to check.     * @return true if the current user has none of the authorities, false otherwise.     */    public static boolean hasCurrentUserNoneOfAuthorities(String... authorities) {        return !hasCurrentUserAnyOfAuthorities(authorities);    }    /**     * Checks if the current user has a specific authority.     *     * @param authority the authority to check.     * @return true if the current user has the authority, false otherwise.     */    public static boolean hasCurrentUserThisAuthority(String authority) {        return hasCurrentUserAnyOfAuthorities(authority);    }    private static Stream&lt;String&gt; getAuthorities(Authentication authentication) {        return authentication.getAuthorities().stream().map(GrantedAuthority::getAuthority);    }}\n\n\n\nPhoto by Philipp Katzenberger onÂ Unsplash\n\n\n\nSecurity Configurations\n\n\nSecurityConfiguration.javaHere we will be saying what kind of apiâ€™s need to be permitted as publicÂ apiâ€™s.\n\n@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true)@Import(SecurityProblemSupport.class)public class SecurityConfiguration extends WebSecurityConfigurerAdapter {    private final TokenProvider tokenProvider;    private final CorsFilter corsFilter;    private final SecurityProblemSupport problemSupport;    public SecurityConfiguration(        TokenProvider tokenProvider,        CorsFilter corsFilter,        SecurityProblemSupport problemSupport    ) {        this.tokenProvider = tokenProvider;        this.corsFilter = corsFilter;        this.problemSupport = problemSupport;    }    @Bean    public PasswordEncoder passwordEncoder() {        return new BCryptPasswordEncoder();    }    @Override    public void configure(WebSecurity web) {        web.ignoring().antMatchers(HttpMethod.OPTIONS, \"/**\").antMatchers(\"/swagger-ui/**\").antMatchers(\"/test/**\");    }    @Override    public void configure(HttpSecurity http) throws Exception {        // @formatter:off        http            .csrf()            .disable()            .addFilterBefore(corsFilter, UsernamePasswordAuthenticationFilter.class)            .exceptionHandling()                .authenticationEntryPoint(problemSupport)                .accessDeniedHandler(problemSupport)        .and()            .headers()            .contentSecurityPolicy(\"default-src 'self'; frame-src 'self' data:; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://storage.googleapis.com; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self' data:\")        .and()            .referrerPolicy(ReferrerPolicyHeaderWriter.ReferrerPolicy.STRICT_ORIGIN_WHEN_CROSS_ORIGIN)        .and()            .permissionsPolicy().policy(\"camera=(), fullscreen=(self), geolocation=(), gyroscope=(), magnetometer=(), microphone=(), midi=(), payment=(), sync-xhr=()\")        .and()            .frameOptions()            .deny()        .and()            .sessionManagement()            .sessionCreationPolicy(SessionCreationPolicy.STATELESS)        .and()            .authorizeRequests()            .antMatchers(\"/api/authenticate\").permitAll()            .antMatchers(\"/api/register\").permitAll()            .antMatchers(\"/api/activate\").permitAll()            .antMatchers(\"/api/account/reset-password/init\").permitAll()            .antMatchers(\"/api/account/reset-password/finish\").permitAll()            .antMatchers(\"/api/admin/**\").hasAuthority(AuthoritiesConstants.ADMIN)            .antMatchers(\"/api/**\").authenticated()            .antMatchers(\"/management/health\").permitAll()            .antMatchers(\"/management/health/**\").permitAll()            .antMatchers(\"/management/info\").permitAll()            .antMatchers(\"/management/prometheus\").permitAll()            .antMatchers(\"/management/**\").hasAuthority(AuthoritiesConstants.ADMIN)        .and()            .httpBasic()        .and()            .apply(securityConfigurerAdapter());        // @formatter:on    }    private JWTConfigurer securityConfigurerAdapter() {        return new JWTConfigurer(tokenProvider);    }}\n\nWebConfigure.javaAllowed domains needs be to added here to avoid CORâ€™s relatedÂ issues\n\n/** * Configuration of web application with Servlet 3.0 APIs. */@Configurationpublic class WebConfigurer implements ServletContextInitializer {    private final Logger log = LoggerFactory.getLogger(WebConfigurer.class);    private final Environment env;    public WebConfigurer(Environment env) {        this.env = env;    }    @Override    public void onStartup(ServletContext servletContext) throws ServletException {        if (env.getActiveProfiles().length != 0) {            log.info(\"Web application configuration, using profiles: {}\", (Object[]) env.getActiveProfiles());        }        log.info(\"Web application fully configured\");    }    @Bean    public CorsFilter corsFilter() {        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();        CorsConfiguration config = new CorsConfiguration();        List&lt;String&gt; list = new ArrayList&lt;&gt;();        list.add(\"*\");        config.setAllowedOriginPatterns(list);        if (!CollectionUtils.isEmpty(config.getAllowedOrigins()) || !CollectionUtils.isEmpty(config.getAllowedOriginPatterns())) {            log.debug(\"Registering CORS filter\");            source.registerCorsConfiguration(\"/api/**\", config);            source.registerCorsConfiguration(\"/management/**\", config);            source.registerCorsConfiguration(\"/v2/api-docs\", config);            source.registerCorsConfiguration(\"/v3/api-docs\", config);            source.registerCorsConfiguration(\"/swagger-resources\", config);            source.registerCorsConfiguration(\"/swagger-ui/**\", config);        }        return new CorsFilter(source);    }}\n\n\n\nPhoto by benjamin lehman onÂ Unsplash\n\n\n\nMongock ChangeLog\n\n\nWe will be using mongock to add default user details to database likeÂ admin.\n\n\nIn application.properties we need to give the path of the class which contains ChangeLog annotation.\n\nspring.data.mongodb.uri=mongodb://localhost:27017/AuthDemomongock.change-logs-scan-package=com.pardhu.authdemo.config.InitialSetupMigration\n\nInitialSetupMigration.java\n\n/** * Creates the initial database setup. */@ChangeLog(order = \"001\")public class InitialSetupMigration {    @ChangeSet(order = \"01\", author = \"initiator\", id = \"01-addAuthorities\")    public void addAuthorities(MongockTemplate mongoTemplate) {        Authority adminAuthority = new Authority();        adminAuthority.setName(AuthoritiesConstants.ADMIN);        Authority userAuthority = new Authority();        userAuthority.setName(AuthoritiesConstants.USER);        mongoTemplate.save(adminAuthority);        mongoTemplate.save(userAuthority);    }    @ChangeSet(order = \"02\", author = \"initiator\", id = \"02-addUsers\")    public void addUsers(MongockTemplate mongoTemplate) {        Authority adminAuthority = new Authority();        adminAuthority.setName(AuthoritiesConstants.ADMIN);        Authority userAuthority = new Authority();        userAuthority.setName(AuthoritiesConstants.USER);        User adminUser = new User();        adminUser.setId(\"user-1\");        adminUser.setLogin(\"admin\");        adminUser.setPassword(\"$2a$10$gSAhZrxMllrbgj/kkK9UceBPpChGWJA7SYIb1Mqo.n5aNLq1/oRrC\");        adminUser.setFirstName(\"admin\");        adminUser.setLastName(\"Administrator\");        adminUser.setEmail(\"admin@localhost\");        adminUser.setActivated(true);        adminUser.setLangKey(\"en\");        adminUser.setCreatedBy(Constants.SYSTEM);        adminUser.setCreatedDate(Instant.now());        adminUser.getAuthorities().add(adminAuthority);        adminUser.getAuthorities().add(userAuthority);        mongoTemplate.save(adminUser);        User userUser = new User();        userUser.setId(\"user-2\");        userUser.setLogin(\"user\");        userUser.setPassword(\"$2a$10$VEjxo0jq2YG9Rbk2HmX9S.k1uZBGYUHdUcid3g/vfiEl7lwWgOH/K\");        userUser.setFirstName(\"\");        userUser.setLastName(\"User\");        userUser.setEmail(\"user@localhost\");        userUser.setActivated(true);        userUser.setLangKey(\"en\");        userUser.setCreatedBy(Constants.SYSTEM);        userUser.setCreatedDate(Instant.now());        userUser.getAuthorities().add(userAuthority);        mongoTemplate.save(userUser);    }}\n\nNow we have two Authorities. Admin and User.While writing an api in controller itself we can annotate like this api can be accessed by admin only using annotations â†’@PreAuthorize(â€œhasAuthority(â€â€ + AuthoritiesConstants.ADMIN + â€œâ€)â€)@PostAuthorize(â€œhasAuthority(â€â€ + AuthoritiesConstants.ADMIN +Â â€œâ€)â€)\n\n\nComplete working git repo is available at GitHubÂ . Also we wrote few login and registerÂ APIâ€™s.\n\n\nThank youâ€¦.\n\n\nPardhu Guttikonda - Medium"
  },
  {
    "objectID": "blog_posts/2023-03-05-binary-tree-data-structure.html",
    "href": "blog_posts/2023-03-05-binary-tree-data-structure.html",
    "title": "Binary Tree Data Structure",
    "section": "",
    "text": "click here to read this in medium\n\nBinary Tree Traversals and problemÂ solving\n\n\n\n\nPhoto by JJ Ying onÂ Unsplash\n\n\n\nğŸ’¡ Common termsÂ :-\n\n\n\n\nfrom upGrad\n\n\n\nIn this article we will be Discussing different tree traversals and problem solving based on these tree traversals.Note: All the code is inÂ JAVA.\n\n\n\n\nPhoto by N. onÂ Unsplash\n\n\n\nğŸŒ´ Tree TraversalsÂ : (Depth First Traversals)\n\n\n\nIn-Order\n\n\nPre-Order\n\n\nPost-Order\n\n\n\nThe goal of these traversals is to visit all the nodes in the binaryÂ tree.\n\n\n\n\nFrom GeeksforGeeks\n\n\n\nIn-Order TraversalÂ :-\n\n\nIn this In-order â†’1. First visit all nodes on the left 2. visit present node 3. Then visit all nodes on theÂ right\n\nvoid inorder(TreeNode root) {        if(root==null){          return;        }        inorder(root.left);        System.out.println(root.val);        inorder(root.right);}\n\nLeetCode submission â†’ https://leetcode.com/problems/binary-tree-inorder-traversal/submissions/679456795/\n\n\nPre-Order Traversal:-\n\n\nHere we follow â†’1. First visit present node2. visit all nodes on the left3. Then visit all nodes on theÂ right\n\nvoid preorder(TreeNode r){        if(r==null){            return;        }        System.out.println(r.val);        preorder(r.left);        preorder(r.right);    }\n\nLeetCode submission â†’ https://leetcode.com/problems/binary-tree-preorder-traversal/submissions/908748627/\n\n\nPost-Order Traversal:-\n\n\nHere we follow â†’1. First visit all nodes on the left 2. Then visit all nodes on the right3. Visit presentÂ node\n\nvoid postOrder(TreeNode r) {        if(r ==null) {            return;        }        postOrder(r.left);        postOrder(r.right);        System.out.println(r.val);    }\n\nLeetCode submission â†’ https://leetcode.com/problems/binary-tree-postorder-traversal/submissions/908750442/\n\n\nğŸ›  Level Order TraversalÂ : (Breadth First Traversal)\n\n\nHere the goal is to print the tree nodes level by level. My Implementation\n\nclass Solution {    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();    public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) {        solve(root,0);        return res;    }    public void solve(TreeNode n,int level){        if(n==null)return ;        if(res.size()&gt;level){            res.get(level).add(n.val);        }else{            List&lt;Integer&gt; t = new ArrayList&lt;&gt;();            t.add(n.val);            res.add(t);        }        solve(n.left,level+1);        solve(n.right,level+1);    }}\n\nLeetCode submission â†’ https://leetcode.com/problems/binary-tree-level-order-traversal/submissions/677053619/\n\n\nBut BFS says to maintain the queue where we first add root node and loop by pop the node and add the children to the queue.Which also gives the similar result with sameÂ runtime.\n\n\nğŸ¥· Example problemÂ 1\n\n\nSum Root to Leaf Numbers - LeetCode\n\n\nHere we need to find a way to get all possible numbers formed by traversing from the root node to each leaf node. Then sum it up. So after observing the problem statement, we can get an idea that we need to use preorder Traversal. But the Question is How we can identify the different paths from root to leaf node? So I got the idea to add an edge case to the preorder traversal saying hey if the present node leaf node here the code forÂ it.\n\nclass Solution {    int sum  = 0;    public int sumNumbers(TreeNode root) {        preorder(root,new StringBuilder());        return sum;    }    public void preorder(TreeNode node, StringBuilder sb){        if (node == null) return;        sb.append(node.val);        if (node.left == null && node.right == null) {            sum += Integer.parseInt(sb.toString());        }        preorder(node.left, sb);        preorder(node.right, sb);        sb.deleteCharAt(sb.length() - 1);    }}// https://leetcode.com/problems/sum-root-to-leaf-numbers/submissions/908758869/\n\nğŸš€ Example problemÂ 2\n\n\nBinary Tree Maximum Path Sum - LeetCode\n\n\nThis is also a very interesting problem. Where we need to find the Path where we can get the maximum Sum by adding the node values. In these case where we need to see all the nodes from the bottom of the tree. We have to go with postOrder kind of approach to solve this problem. Here is my solution.\n\nclass Solution {    int final_max = Integer.MIN_VALUE;    public int maxPathSum(TreeNode root) {        solve(root);        return final_max;    }    public int solve(TreeNode root){        if(root==null){return 0;}        int leftMax = solve(root.left);        int rightMax = solve(root.right);        int send_top = Math.max(Math.max(leftMax,rightMax)+root.val,root.val);        int comMax = Math.max(leftMax+rightMax+root.val,send_top);        final_max = Math.max(final_max,comMax);        return send_top;    }}// https://leetcode.com/problems/binary-tree-maximum-path-sum/submissions/909178204/\n\nThank youâ€¦!\n\n\n\nPardhu Guttikonda - Medium\n\n\npropardhu - LeetCode Profile"
  },
  {
    "objectID": "blog_posts/2022-10-07-cucumber-with-selenium-automation.html",
    "href": "blog_posts/2022-10-07-cucumber-with-selenium-automation.html",
    "title": "Cucumber with Selenium Automation",
    "section": "",
    "text": "click here to read this in medium\n\nProject setup for cucumber Selenium automation using page objectÂ modal\n\n\n\n\nPhoto by Kaleidico onÂ Unsplash\n\n\n\nSteps to be followedÂ â†’\n\n\n\nCreate a maven project (I will be using IntelliJ).ğŸ› \n\n\nAdd the dependences.ğŸ§â€â™‚ï¸\n\n\nCreate the Runner JAVAÂ file.ğŸ’¡\n\n\nCreate as per the Runner file structure.â³\n\n\nRun tests using feature filesÂ âœ…\n\n\n\nCreate a maven project in IntelliJ without any dependencies inÂ it\n\n\n\nJust provide the project name and location to be stored in the process of creation mavenÂ project.\n\n\n\n\n\nPhoto by Jeremy Bezanger onÂ Unsplash\n\n\n\nAdding Dependences to pom.xml â†’ Given pom.xmlÂ below\n\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  &lt;groupId&gt;org.example&lt;/groupId&gt;  &lt;artifactId&gt;amazon-automation&lt;/artifactId&gt;  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  &lt;properties&gt;    &lt;maven.compiler.source&gt;16&lt;/maven.compiler.source&gt;    &lt;maven.compiler.target&gt;16&lt;/maven.compiler.target&gt;  &lt;/properties&gt;  &lt;dependencies&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.seleniumhq.selenium&lt;/groupId&gt;      &lt;artifactId&gt;selenium-java&lt;/artifactId&gt;      &lt;version&gt;4.3.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;io.cucumber&lt;/groupId&gt;      &lt;artifactId&gt;cucumber-gherkin&lt;/artifactId&gt;      &lt;version&gt;7.6.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.testng&lt;/groupId&gt;      &lt;artifactId&gt;testng&lt;/artifactId&gt;      &lt;version&gt;6.14.3&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;io.cucumber&lt;/groupId&gt;      &lt;artifactId&gt;cucumber-testng&lt;/artifactId&gt;      &lt;version&gt;7.6.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.seleniumhq.selenium&lt;/groupId&gt;      &lt;artifactId&gt;selenium-chrome-driver&lt;/artifactId&gt;      &lt;version&gt;4.3.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;io.cucumber&lt;/groupId&gt;      &lt;artifactId&gt;cucumber-gherkin&lt;/artifactId&gt;      &lt;version&gt;7.6.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;      &lt;groupId&gt;io.cucumber&lt;/groupId&gt;      &lt;artifactId&gt;cucumber-java&lt;/artifactId&gt;      &lt;version&gt;7.6.0&lt;/version&gt;    &lt;/dependency&gt;  &lt;/dependencies&gt;&lt;/project&gt;\n\nAs per the given pom.xml file add the dependencies.\n\n\nAdd Runner.JAVA to the projectÂ â†’\n\n\nRunner.java\n\n@CucumberOptions(    features = \"src/test/resources/features\",    glue = \"StepDefinitions\",    plugin = {        \"pretty\",        \"html:target/cucumber-reports/cucumber-pretty\",        \"json:target/cucumber-reports/CucumberTestReport.json\",        \"timeline:target/test-output-thread/\"    })public class Runner extends AbstractTestNGCucumberTests {  @Override  @DataProvider(parallel = true)  public Object[][] scenarios() {    return super.scenarios();  }  @BeforeSuite  public void beforeSuite() {    System.out.println(\"================ BEFORE SUITE==========\");  }  @AfterSuite  public void afterSuite() {    System.out.println(\"================ AFTER SUITE ==========\");  }}\n\n\nIn the above file we need to specify the path there the feature files are located in the project.(src/test/resources/features)\n\n\nAlso we have to mention the package name there the steps will be writen in the project.(StepDefinitions)\n\n\n\nCreate page object modalsÂ â†’\n\n\n\nMake BasePage class to place common methods which can be used to all the pageÂ classes.\n\n\npublic class BasePage {  private static WebDriver driver;  public static final int TIMEOUT_PERIOD_LONG = 30;  public BasePage(WebDriver driver) {    this.driver = driver;  }  public WebElement waitForElement(By element, long timeout) {    WebElement myElement = null;    try {      myElement = new WebDriverWait(driver, Duration.ofSeconds(timeout)).until(ExpectedConditions.visibilityOfElementLocated(element));    } catch (TimeoutException toe) {      System.out.println(toe);    } finally {      if (myElement == null) {        String str = \"Unable to find the WebElement in the web page by using its locator\";        System.out.println(str);      }    }    return myElement;  }  public void waitForElementToBeVisible(ById element){    WebElement myElement = new WebDriverWait(driver, Duration.ofSeconds(5)).until(ExpectedConditions.visibilityOfElementLocated(element));    WebDriverWait wait= new WebDriverWait(driver,Duration.ofSeconds(5));    wait.until(ExpectedConditions.visibilityOf(myElement));  }  public void waitForElementToBeVisible(ByXPath element){    WebElement myElement = new WebDriverWait(driver, Duration.ofSeconds(5)).until(ExpectedConditions.visibilityOfElementLocated(element));    WebDriverWait wait= new WebDriverWait(driver,Duration.ofSeconds(5));    wait.until(ExpectedConditions.visibilityOf(myElement));  }}\n\n\nCreating page class like shown below. all the page classes will be extending the BasePageÂ class.\n\n\npublic class HomePage extends BasePage {  public HomePage(WebDriver driver) {    super(driver);    PageFactory.initElements(driver, this);  }  public final ById searchInput = new ById(\"twotabsearchtextbox\");  public WebElement getSearchInput() {    return waitForElement(searchInput,30);  }  public void waitTillSearchVisible() {    waitForElementToBeVisible(searchInput);  }}\n\nSearchResultPage.class\n\npublic class SearchResultPage extends BasePage {\npublic SearchResultPage(WebDriver driver) {        super(driver);        PageFactory.initElements(driver, this);    }\npublic final ById logoBtn = new ById(\"nav-logo-sprites\");\npublic final ByXPath item = new ByXPath(\"/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[4]/div/div/div/div/div[2]/div[2]/h2/a\");\npublic WebElement getItem() {        return waitForElement(item, 30);    }\npublic WebElement getLogoBtn() {        return waitForElement(logoBtn, 30);    }\npublic void waitTillLogoVisible() {        waitForElementToBeVisible(logoBtn);    }}\n\nNow we need to create a package stepdefinition and write all the steps which will be used in featureÂ file.\n\n\nHooks.java\n\npublic class Hooks {    public static WebDriver driver;\n@Before    public void OpenDriver() {        System.setProperty(\"webdriver.chrome.driver\", \"src/test/resources/drivers/mac/chromedriver\");        driver = new ChromeDriver();    }\n@After    public void closeDriver() {        driver.close();    }}\n\nHomePageSteps.java\n\npublic class HomePageSteps {\nprivate final HomePage homePage;\npublic HomePageSteps() {        this.homePage = PageObjectManager.pageFactory().getHomePage(Hooks.driver);    }\n@Given(\"I'm on amazon\")    public void onAmazon() {        Hooks.driver.get(\"https://www.amazon.com/\");        this.homePage.waitTillSearchVisible();    }\n@When(\"I select Search for {string}\")    public void enterSearch(String enterText) {        WebElement searchInput = this.homePage.getSearchInput();        searchInput.clear();        searchInput.sendKeys(enterText);        searchInput.sendKeys(Keys.ENTER);    }}\n\nSearchPageSteps.java\n\npublic class SearchPageSteps {    public final SearchResultPage searchResultPage;\npublic SearchPageSteps() {        this.searchResultPage = PageObjectManager.pageFactory().getSearchResultPage(Hooks.driver);    }\n@Then(\"I'm on result page\")    public void onResultPage() {        this.searchResultPage.waitTillLogoVisible();    }\n@And(\"I click on item\")    public void clickOnItem() throws InterruptedException {        WebElement btn = this.searchResultPage.getItem();        btn.click();        Hooks.driver.wait(300);    }}\n\nFeatures file\n\nFeature: Search item Scenario: Search for given item   Given I'm on amazon   When I select Search for \"jackets\"   Then I'm on result page     And I click on item\n\nNow according to the statements in feature file Steps will be executed.\n\n\ncomplete code is available at https://github.com/propardhu/cucumber-seleniumÂ â€¦!"
  },
  {
    "objectID": "publications/PhysiologicalSignalCompression.html",
    "href": "publications/PhysiologicalSignalCompression.html",
    "title": "Real-Time Diagnostic Integrity Meets Efficiency: A Novel Platform-Agnostic Architecture for Physiological Signal Compression",
    "section": "",
    "text": "IEEE BSN 2024\nHead-based signals such as EEG, EMG, EOG, and ECG collected by wearable systems will play a pivotal role in clinicaldiagnosis, monitoring, and treatment of important brain disorder diseases. However, the real-time transmission of thesignificant corpus physiological signals over extended periods consumes substantial power and time, limiting the viability of battery-dependent physiological monitoring wearables.This paper presents a novel deep-learning framework employing a variational autoencoder (VAE) for physiologicalsignal compression to reduce wearablesâ€™ computational complexity and energy consumption. Our approach achieves animpressive compression ratio of 1:293 specifically for spectrogram data, surpassing state-of-the-art compression techniques such as JPEG2000, H.264, Direct Cosine Transform(DCT), and Huffman Encoding, which do not excel in handling physiological signals. We validate the efficacy of thecompressed algorithms using collected physiological signalsfrom real patients in the Hospital and deploy the solutionon commonly used embedded AI chips (i.e., ARM Cortex V8and Jetson Nano). The proposed framework achieves a 91%seizure detection accuracy using XGBoost, confirming theapproachâ€™s reliability, practicality, and scalability. arxiv link"
  },
  {
    "objectID": "publications/AdversarialAttack.html",
    "href": "publications/AdversarialAttack.html",
    "title": "Demonstration of an Adversarial Attack Against a Multimodal Vision Language Model for Pathology Imaging",
    "section": "",
    "text": "IEEE ISBI 2024\nIn the context of medical artificial intelligence, this study explores the vulnerabilities of the Pathology Language-Image Pretraining (PLIP) model, a Vision Language Foundation model, under targeted attacks. Leveraging the Kather Colon dataset with 7,180 H&E images across nine tissue types, our investigation employs Projected Gradient Descent (PGD) adversarial perturbation attacks to induce misclassifications intentionally. The outcomes reveal a 100% success rate in manipulating PLIPâ€™s predictions, underscoring its susceptibility to adversarial perturbations. The qualitative analysis of adversarial examples delves into the interpretability challenges, shedding light on nuanced changes in predictions induced by adversarial manipulations. These findings contribute crucial insights into the interpretability, domain adaptation, and trustworthiness of Vision Language Models in medical imaging. The study emphasizes the pressing need for robust defenses to ensure the reliability of AI models. The source codes for this experiment can be found at https://github.com/jaiprakash1824/VLM_Adv_Attack. arxiv link"
  },
  {
    "objectID": "pubs.html",
    "href": "pubs.html",
    "title": "Publications",
    "section": "",
    "text": "Real-Time Diagnostic Integrity Meets Efficiency: A Novel Platform-Agnostic Architecture for Physiological Signal Compression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpatialVisVR:An Immersive, Multiplexed Medical Image Viewer With Contextual Similar-Patient Search\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDemonstration of an Adversarial Attack Against a Multimodal Vision Language Model for Pathology Imaging\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  }
]