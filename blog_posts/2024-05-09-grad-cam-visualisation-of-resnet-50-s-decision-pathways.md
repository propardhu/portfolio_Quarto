---
title: "Grad-CAM Visualisation of ResNet-50â€™s Decision Pathways"
date: 2024-05-09
reading-time: "5 min read"
categories: grad-cam
image: https://cdn-images-1.medium.com/max/800/0*i27wef8IfiIomVpR.jpg
---

[click here to read this in medium](https://guttikondaparthasai.medium.com/grad-cam-visualisation-of-resnet-50s-decision-pathways-d4d6a85f5a57?source=rss-2c47946b91eb------2)

<p>Tracing ResNet-50 Focus trands with Grad-CAM.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/800/0*i27wef8IfiIomVpR.jpg" /><figcaption><a href="https://azati.ai/image-detection-recognition-and-classification-with-machine-learning/">https://azati.ai/image-detection-recognition-and-classification-with-machine-learning/</a></figcaption></figure><h4>Understanding How AI Sees theÂ WorldğŸŒ</h4><p>Imagine an AI as an artist trying to paint a picture but first needing to decide what part of a scene is worth focusing on. In this article, we explore a tool called Grad-CAM, which helps us visualize what catches the AIâ€™s attention when it looks at an image. This tool is particularly useful for understanding complex image recognition models like ResNet-50, a type of deep neural network renowned for its accuracy in identifying objects inÂ images.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/500/1*Lk3_wpLJaWUfrYHMvA1P4Q.jpeg" /><figcaption>our inputÂ Image</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/500/1*aseruXZUZ9k2egMOPSQzSw.png" /><figcaption>sample output</figcaption></figure><h4>Getting StartedğŸ™ŒğŸ»</h4><p>To start, we need an image. Think of it as the scene our AI artist is going to paint. We use a standard JPEG image for this purpose. Our AI, powered by a model called ResNet-50, processes this image not just as a whole but looks deeply at various parts to decide what itÂ sees.</p><h4>Peeking Into the AIâ€™s Mind (Grad-Cam)ğŸ’¡</h4><p>To peek into what the AI is focusing on, we use Grad-CAM. This tool generates heatmaps that overlay on the original image. These heatmaps change color in areas where the AI is paying more attention. Thus, by looking at these heatmaps, we can understand which parts of the image are most important for the AIâ€™s decision-making.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*AG_M2Cgvhhv2yXyT" /><figcaption>Photo by <a href="https://unsplash.com/@clemensvanlay?utm_source=medium&amp;utm_medium=referral">Clemens van Lay</a> onÂ <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure><h4>Step-by-Step Through theÂ Code:-</h4><pre>.<br />â”œâ”€â”€ ResNet50Vis.ipynb<br />â”œâ”€â”€ sample.jpeg<br />â”œâ”€â”€ result.gif(animated gif is here result)<br />â””â”€â”€ images<br />    â””â”€â”€ (genarated images will be here)</pre><p>Here is the file structure so we have only ResNet50Vis.ipynb and sample.jpeg files will be in the working directory.</p><p><strong>Prepare Utils and Model Wrapping:<br /></strong>Here we are creatingÂ reusable</p><pre>import warnings<br />warnings.filterwarnings('ignore')<br />from torchvision import transforms<br />from datasets import load_dataset<br />from pytorch_grad_cam import run_dff_on_image, GradCAM<br />from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget<br />from pytorch_grad_cam.utils.image import show_cam_on_image<br />from PIL import Image<br />import numpy as np<br />import cv2<br />import torch<br />import imageio<br />from typing import List, Callable, Optional<br /><br />image = Image.open('./sample.jpeg')<br />img_tensor = transforms.ToTensor()(image)<br /><br />class HuggingfaceToTensorModelWrapper(torch.nn.Module):<br />    def __init__(self, model):<br />        super(HuggingfaceToTensorModelWrapper, self).__init__()<br />        self.model = model<br /><br />    def forward(self, x):<br />        return self.model(x).logits<br /><br />def category_name_to_index(model, category_name):<br />    name_to_index = dict((v, k) for k, v in model.config.id2label.items())<br />    return name_to_index[category_name]<br />    <br />def run_grad_cam_on_image(model: torch.nn.Module,<br />                          target_layer: torch.nn.Module,<br />                          targets_for_gradcam: List[Callable],<br />                          reshape_transform: Optional[Callable],<br />                          input_tensor: torch.nn.Module=img_tensor,<br />                          input_image: Image=image,<br />                          method: Callable=GradCAM):<br />    with method(model=HuggingfaceToTensorModelWrapper(model),<br />                 target_layers=[target_layer],<br />                 reshape_transform=reshape_transform) as cam:<br />        repeated_tensor = input_tensor[None, :].repeat(len(targets_for_gradcam), 1, 1, 1)<br /><br />        batch_results = cam(input_tensor=repeated_tensor,<br />                            targets=targets_for_gradcam)<br />        results = []<br />        for grayscale_cam in batch_results:<br />            visualization = show_cam_on_image(np.float32(input_image)/255,<br />                                              grayscale_cam,<br />                                              use_rgb=True)<br />            visualization = cv2.resize(visualization,<br />                                       (visualization.shape[1]//2, visualization.shape[0]//2))<br />            results.append(visualization)<br />        return np.hstack(results)<br />    <br />    <br />def print_top_categories(model, img_tensor, top_k=5):<br />    logits = model(img_tensor.unsqueeze(0)).logits<br />    indices = logits.cpu()[0, :].detach().numpy().argsort()[-top_k :][::-1]<br />    for i in indices:<br />        print(f&quot;Predicted class {i}: {model.config.id2label[i]}&quot;)</pre><p><strong>Target IdentificationÂ :</strong></p><p>now lets set the target label for which we will be genarating heat maps. As per our input image our target lable will cairn, cairnÂ terrier</p><pre>from transformers import ResNetForImageClassification<br />model = ResNetForImageClassification.from_pretrained(&quot;microsoft/resnet-50&quot;)<br />targets_for_gradcam = [ClassifierOutputTarget(category_name_to_index(model, &quot;cairn, cairn terrier&quot;))]</pre><p><strong>Running Grad-CAM:</strong></p><p>Here we will be running gradCam on every stage of resnet50 and store the heatmap image to list_of_images.</p><pre>list_of_images = []<br />for i in model.resnet.encoder.stages:<br />    for j in i.layers:<br />        target_layer = j<br />        list_of_images.append(Image.fromarray(run_grad_cam_on_image(model=model,<br />                      target_layer=target_layer,<br />                      targets_for_gradcam=targets_for_gradcam,<br />                      reshape_transform=None)))<br />print_top_categories(model, img_tensor)</pre><p><strong>Visualization and Animation:</strong></p><p>Great now can creat gif with our list ofÂ images.</p><pre>image_files = []<br />for i, img in enumerate(list_of_images):<br />    path = f'images/temp_image_{i}.png'<br />    img.save(path)<br />    image_files.append(path)<br />with imageio.get_writer('my_animation.gif', mode='I', duration=0.5) as writer:<br />    for filename in image_files:<br />        image = imageio.imread(filename)<br />        writer.append_data(image)<br />from IPython.display import Image, display<br />display(Image(filename='./my_animation.gif'))</pre><h4>Results:</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/250/1*Mhpf1CK8-YGJ4h5BWGmiWw.gif" /><figcaption>result gif</figcaption></figure><h4>Insights:</h4><p>By using the gradient values of each pixel in the image, we have generated heatmaps for all 15 stages of the encoder. These 15 heatmaps have been collected in a folder named â€˜images.â€™ Subsequently, we created a GIF that illustrates how an algorithm shifts its focus within anÂ image.</p><p>Complete code is avaliable at <a href="https://github.com/propardhu/ResNet_50_Vis"><strong>https://github.com/propardhu/ResNet_50_Vis</strong></a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*G4nxyFNUBq2gKjRd" /><figcaption>Photo by <a href="https://unsplash.com/@kellysikkema?utm_source=medium&amp;utm_medium=referral">Kelly Sikkema</a> onÂ <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure><p><a href="https://medium.com/@guttikondaparthasai">Pardhu Guttikonda - Medium</a></p><img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d4d6a85f5a57" width="1" />
