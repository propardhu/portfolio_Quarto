---
title: "Image Processing using CNN"
date: 2023-07-06
reading-time: "5 min read"
categories: convolutional-neural-net
image: https://cdn-images-1.medium.com/max/570/1*jsfuRf-bxgIe2rbKMlW34g.gif
---

[click here to read this in medium](https://guttikondaparthasai.medium.com/image-processing-using-cnn-4285a1cd4a1c?source=rss-2c47946b91eb------2)

<p>Convolutional NeuralÂ Network</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/570/1*jsfuRf-bxgIe2rbKMlW34g.gif" /><figcaption>medium</figcaption></figure><h3>Basics â†’</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*0aXDT66-F3PL5FPK" /><figcaption>Photo by <a href="https://unsplash.com/@sebbill?utm_source=medium&amp;utm_medium=referral">Sebastian Bill</a> onÂ <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure><h4>What is anÂ Image?</h4><p>An image is nothing but an array of elements called pixels. A pixel is the smallest unit of a digital image or graphic that can be displayed and represented on a digital display device, which ranges between 0 and 255.<br />So, image is nothing but an n * 2d Array with values ranging from 0 to 255.<br />NoteÂ :- n depends on type of image, if the image is represented in RGB the n will be inÂ 3.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*PsmVDdnBT1XZFn2H" /><figcaption>Photo by <a href="https://unsplash.com/@jontyson?utm_source=medium&amp;utm_medium=referral">Jon Tyson</a> onÂ <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure><p>We are using MNIST dataset each image is a 28X28 pixel square. Which means we will be having 1 * 28 * 28 resolution images in our dataset. Letâ€™s get the dataset and display theÂ imageðŸ˜ƒ.</p><pre>import tensorflow as tf<br />import numpy as np<br />from matplotlib import pyplot as plt<br />from tensorflow.keras import utils as np_utils<br />(X_train,y_train),(X_test,y_test) = tf.keras.datasets.mnist.load_data()<br />X_test = X_test.reshape(X_test.shape[0], 1,28,28).astype('float32')<br />X_test = X_test/255<br />y_test = np_utils.to_categorical(y_test)<br />y_test = y_test/255<br />first_image = np.array(X_test[0], dtype='float')<br />pixels = first_image.reshape((28, 28))<br />plt.imshow(pixels, cmap='gray')<br />plt.show()</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/416/1*v5DgiJRMj6Z_r6qRvq_lFw.png" /></figure><h3>IntroductionÂ :-</h3><h4><strong>CNN contains three type of layers whichÂ are</strong></h4><p><strong>Convolutional Layerâ€Š</strong>â€”â€ŠHere we will be extracting the features present in the image. Example we can find all the horizontal lines present in the image using dot product of our horizontal matrix with the image matrix, then the resultant matrix will only contain the horizontal lines.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*FjBn6-MCNReZbi_LdvNKlw.png" /><figcaption>horizontal lines from the image source codingÂ lane</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ulfFYH5HbWpLTIfuebj5mQ.gif" /><figcaption>Illustration of Convolution Operation(<a href="https://miro.medium.com/v2/resize:fit:2340/1*Fw-ehcNBR9byHtho-Rxbtw.gif">source</a>)</figcaption></figure><p><strong>Pooling Layer</strong>â€Šâ€”â€ŠIt is used to reduce the image size. By simply doing dot product for the image with a fixedÂ slider.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*YuxsVCChkKv051ivcV4hnw.png" /><figcaption>from codingÂ lane</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*rgO9lIs8AarOTZ5LRo3ISw.png" /><figcaption>from codingÂ lane</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*lBOGTvB0Txsgx-up3uRHfA.png" /><figcaption>from codingÂ lane</figcaption></figure><p><strong>Fully-Connected layer</strong>â€Šâ€”â€ŠHere it flattens the pixels and learns to associate features by forming all the combinations of flattenÂ objects.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*F-1N3QaQypVO9jqE" /><figcaption>Photo by <a href="https://unsplash.com/@medion4you?utm_source=medium&amp;utm_medium=referral">Norbert Braun</a> onÂ <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure><h3>Letâ€™s jump on theÂ task</h3><p>we have a dataset which contains digits from 0 to 9 in the form of images. Our task is to build a CNN model to predict the digit. So out CNN layers will be in thisÂ form.</p><p>Output Layer<br />(10 outputs)<br />Hidden Layer<br />(128 neurons)<br />Flatten Layer<br />Dropout Layer<br />20%<br />Max Pooling Layer<br />2Ã—2<br />Convolutional Layer<br />32 maps, 5Ã—5<br />Visible Layer<br />1x28x28</p><ol><li>The first hidden layer is a Convolutional layer called Convolution2D. It consists of 32 feature maps with a size of 5Ã—5 and uses the rectifier activation function.</li><li>The next layer is a pooling layer called MaxPooling2D. It performs 2Ã—2 pooling, which means it takes the maximum value from a 2Ã—2 grid ofÂ values.</li><li>A dropout layer follows, which helps with regularization. It randomly excludes 20% of the neurons in the layer during training to prevent overfitting.</li><li>The fifth layer is a flattened layer called Flatten. It converts the 2D matrix data from the previous layer into a 1D vector, allowing it to be processed by a fully connected layer.</li><li>Next, there is a fully connected layer with 128 neurons and the rectifier activation function.</li><li>Finally, the output layer consists of 10 neurons, representing the 10 classes in the classification task. It uses the softmax activation function to produce probability-like predictions for eachÂ class.</li></ol><h3>Coding it:</h3><pre>import numpy as np<br />from matplotlib import pyplot as plt<br />from tensorflow.keras.utils import to_categorical<br />from keras.models import Sequential<br />from keras.layers import Dense<br />from tensorflow.keras import utils as np_utils<br />from keras.layers import Dropout<br />from keras.layers import Flatten<br />from tensorflow.keras.layers import Conv2D<br />from tensorflow.keras.layers import MaxPooling2D<br />import tensorflow as tf<br />import time<br /><br />#importing and preprocessing<br />(X_train,y_train), (X_test, y_test)= tf.keras.datasets.mnist.load_data()<br />X_train=X_train.reshape(X_train.shape[0], 1,28,28).astype('float32')<br />X_test=X_test.reshape(X_test.shape[0], 1,28,28).astype('float32')<br /><br />X_train=X_train/255<br />X_test=X_test/255<br />y_train = np_utils.to_categorical(y_train)<br />y_test= np_utils.to_categorical(y_test)<br />num_classes=y_train.shape[1]<br />print(num_classes)<br /><br />#prepare your model<br />def cnn_model():<br />    model=Sequential()<br />    # Convolutional Layer 32 map 5X5 and input 1 * 28 * 28<br />    model.add(Conv2D(32,5,5, padding='same',input_shape=(1,28,28), activation='relu'))<br />    # Max Pooling Layer 2 X 2<br />    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))<br />    # Dropout Layer 20%<br />    model.add(Dropout(0.2))<br />    # Flatten Layer<br />    model.add(Flatten())<br />    # Hidden Layer 128 neurons<br />    model.add(Dense(128, activation='relu'))<br />    # Output Layer<br />    model.add(Dense(num_classes, activation='softmax'))<br />    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])<br />    return model<br /><br />t1 = time.time_ns()<br />model=cnn_model()<br />model.fit(X_train, y_train, validation_data=(X_test,y_test),epochs=10, batch_size=200, verbose=2)<br />t2 = time.time_ns()<br />score= model.evaluate(X_test, y_test, verbose=0)<br />t3 = time.time_ns()<br />train_time = t2-t1<br />evaluavation_time = t3-t2<br />print('The accuracy is: %.2f%%'%(score[1]))<br />print(f'training time {train_time}, evaluvation time {evaluavation_time}')<br /><br />first_image = np.array(X_test[0], dtype='float')<br />pixels = first_image.reshape((28, 28))<br />plt.imshow(pixels, cmap='gray')<br />plt.show()<br />t4 = time.time_ns()<br />test_input = first_image.reshape((-1, 1, 28, 28))<br />k = model.predict(test_input).tolist()<br />t5 = time.time_ns()<br />print(f'predicted output : {k[0].index(max(k[0]))}')<br />print(f'actual output : {y_test[0]}')<br />print(f'prediction time {t5-t4}')</pre><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*8GGWUYnv97EbOugZ" /><figcaption>Photo by <a href="https://unsplash.com/es/@jrarce?utm_source=medium&amp;utm_medium=referral">Ricardo Arce</a> onÂ <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure><h3>Results</h3><p><strong>Accuracy</strong>â€Šâ€”â€Š97%<br /><strong>Training run time</strong>â€Šâ€”â€Š7.2892 Sec<br /><strong>Evaluation run time</strong>â€Šâ€”â€Š0.186776 Sec<br /><strong>Prediction run time (for digit 7)â€Š</strong>â€”â€Š0.033601Â Sec</p><p>Complete code is available in my <a href="https://github.com/propardhu/Pandas_Play/blob/main/CNN_mnist.ipynb">GitHub</a> (<a href="https://github.com/propardhu/Pandas_Play/blob/main/CNN_mnist.ipynb">https://github.com/propardhu/Pandas_Play/blob/main/CNN_mnist.ipynb</a>)</p><a href="https://medium.com/media/9602ed028d76e3f631dae05408c7e2cd/href">https://medium.com/media/9602ed028d76e3f631dae05408c7e2cd/href</a><ul><li><a href="https://guttikondaparthasai.medium.com/">Pardhu Guttikonda - Medium</a></li><li><a href="https://github.com/propardhu/Pandas_Play/blob/main/CNN_mnist.ipynb">Pandas_Play/CNN_mnist.ipynb at main Â· propardhu/Pandas_Play</a></li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*CS_Pg0DSbPEWFhcA" /><figcaption>Photo by <a href="https://unsplash.com/@priscilladupreez?utm_source=medium&amp;utm_medium=referral">Priscilla Du Preez</a> onÂ <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></figcaption></figure><img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4285a1cd4a1c" width="1" />
